# Varying-intercept models


## Objectives

- Introduce multilevel structures
- Introduce varying intercept models


```{r load_packages_vary_intercept, message = F, results = 'hide'}

library(pacman)

p_load(tidyverse, here, janitor, purrr, viridis, brms, tidybayes, bayesplot,
       modelr, forcats)

theme_set(theme_bw())

```

## Reading

The following materials are recommended pre-readings before starting this tutorial. 

- Chapter 12 "Multilevel Models" from [**Statistical Rethinking** by Richard McElreath](https://xcelab.net/rm/statistical-rethinking/).
- Chapter 12 "Multilevel linear models: the basics" from [**Data Analysis Using Regression and Multilevel/Hierarchical Models** by Gelman and Hill](https://www.cambridge.org/core/books/data-analysis-using-regression-and-multilevelhierarchical-models/32A29531C7FD730C3A68951A17C9D983).  
- OPTIONAL Chapter 11 "Multilevel structures" from [**Data Analysis Using Regression and Multilevel/Hierarchical Models** by Gelman and Hill](https://www.cambridge.org/core/books/data-analysis-using-regression-and-multilevelhierarchical-models/32A29531C7FD730C3A68951A17C9D983).  

This lesson is a major conceptual leap forward in our studies. I highly recommend you check out [this interactive visualization](http://mfviz.com/hierarchical-models/) to get a handle on what we're going to be covering in this lesson. Also, if you have not already read the [lesson on multiple predictors](#reg-multi) or the [lesson on interactions](#interactions), please do as there are strong conceptual similarities between those lessons and multilevel models.


## Introduction 


When collecting or analyzing data, it is not uncommon to identify groupings or nested structures underpinning our data. For example, we might have multiple measurements from the same individual or species, species co-occurrences across multiple temporal windows or localities, species from different ecological guilds, etc. Structured data is very common but the knowledge of how to model it properly is rare.

In our previous lessons we've covered how to include [categorical predictors](#dummy) in our regression models as a way to encode some of this known structure in our data. By relying on dummy variables, however, we are forcing our model to consider the different states independently because their parameters are statistically independent even though we know of the logical relationship between them. The reality of this is that we are ignoring information that could be relevant to our understanding. But we want models that use all of this information, like that omnivory and herbivory are types of trophic levels and not completely independent. 

We want inferences about one state to possibly inform inferences about another. Importantly, this does not mean treating all states as identical. Instead we want to understand the distribution of states within a group as well as the individual states themselves. For example, this would mean the estimating the average and spread among the trophic levels as well as the individual values for each trophic level. Simultaneously inference means we can transfer information between states and improve our inferences.

Multilevel models are models that remember features of each (identified) group in the data as they learn about all of the states. The amount of variation among the clusters determines how much the model pools information across clusters and improving our overall estimates. 

Pragmatic benefits of multilevel modeling

- **Improved estimates for repeat sampling.** When more than one observation arises from the same individual, location, or time, then traditional single-level models either maximally underfit or overfit the data.  By identifying and modeling that repeated sampling, we can improve our estimates of the variable being measured and propagate our uncertainty about that parameter. 
- **Improved estimates for imbalance in sampling.** When some individuals, locations, or times are sampled more than others, multilevel models automatically cope with differeing uncertainty across these clusters. This prevents over-sampled clusters from unfairly dominating inference.
- **Estimates of variation.** If our research questions include variation among individuals or other groups within the data, then multilevel models are a big help because they model variation explicits. Dummy coding does not include the variation between the states, which is potentially very useful information. 
- **Avoid averaging, retaining variation.** Too often people summarize repeated sampling by pre-averaging some data to construct their variables. This can be dangerous because averaging removes variation. Also, there are lots of ways to average data. Averaging manufactures false confidence and introduces an arbitrary data transform. Multilevel models allow us to preserve our uncertainty and avoid unnecessary and unprincipled data transforms.

Each of the states are considered realizations from the same population. The probability distribution for the population acts as the prior for each of the states. Except this prior isn't exactly the same as we're used to. Instead, this prior is actually learned from the data.

Multilevel regression should be the default approach to regression. In the vast majority of cases, multilevel models are superior single-level models. Once you grasp the basics of the multilevel modeling strategy it becomes much easier to incorporate related tricks such as allowing for measurement error in the data and even modeling missing data! Defining, implementing, and understanding a multilevel model is in general more complicated than a single-level model. We have to define the distribution of our states -- something that sounds a lot harder than it is. Also, multilevel models are a lot harder to fit than most single-level models. This means more time tuning our MCMC algorithm, something we've so far been ableo to avoid. Finally, because multilevel models by their nature make statements at different "levels" of the data, they can be difficult for people to understanding. People rarely think about a population and the individual values within that population simultaneously.



## A basic model with categorical predictor

The basic form of a multilevel model is termed a "varying-intercept" model. This type of model is conceptually very similar to a model with a [multistate categorical predictor](#dummy), but instead of including $k - 1$ binary predcitors in our model, we are defining a model where each state has its own intercept, and those intercepts share a common prior distribution.

For this example we're going to explore how mammal species population denisty varies as a function of species trophic level. All this data is from the [PanTHERIA dataset](http://www.esapubs.org/archive/ecol/E090/184/default.htm) database, a large collection of trait data for extant mammals. If you need a refresher on the definitions of the variables within this dataset, you can review the [data dictionary](http://esapubs.org/archive/ecol/E090/184/metadata.htm). 

As per usual, let's import the PanTHERIA dataset, clean it up a bit, and prepare it for further exploration and analysis. Importantly, I'm recoding `trophic_level` so that "omnivore" is the default state.

```{r pantheria_multilevel}

pantheria <- read_tsv(here('data', 'PanTHERIA_1-0_WR05_Aug2008.txt'), 
                      na = '-999.00') %>%
  clean_names() %>% 
  mutate(mass_log = log(x5_1_adult_body_mass_g),
         range_group_log = log(x22_1_home_range_km2),
         range_indiv_log = log(x22_2_home_range_indiv_km2),
         density_log = log(x21_1_population_density_n_km2),
         activity_cycle = case_when(x1_1_activity_cycle == 1 ~ 'nocturnal',
                                    x1_1_activity_cycle == 2 ~ 'mixed',
                                    x1_1_activity_cycle == 3 ~ 'diurnal'),
         trophic_level = case_when(x6_2_trophic_level == 1 ~ 'herbivore',
                                   x6_2_trophic_level == 2 ~ 'omnivore',
                                   x6_2_trophic_level == 3 ~ 'carnivore')) %>%
  drop_na(mass_log, density_log, trophic_level) %>%
  mutate(mass_stan = arm::rescale(mass_log), # center and scale
         trophic_level = fct_infreq(trophic_level)) # reorder by frequency

```

To start, let's write out a linear regression model where population density $y$ is predicted by trophic level dummy coded to two binary predictors: herbivory $h$ and carnivory $c$.

$$
\begin{align}
y_{i} &= \text{Normal}(\alpha + \beta_{h} h_{i} + \beta_{c} c_{i}, \sigma) \\
\alpha &\sim \text{Normal}(0, 10) \\
\beta_{h} &\sim \text{Normal}(0, 5) \\
\beta_{c} &\sim \text{Normal}(0, 5) \\
\sigma &\sim \text{Cauchy}^{+}(5) \\
\end{align}
$$

My guess is that this should look familiar. This is the way we've been writing out regression models with a multistate categorical predictor so far. 

$\beta_{h}$ and $\beta_{c}$ are modeled independently, which means that any information we learn about one will have no effect on our learning for the other. We know that the different trophic levels are part of the same category and are certaintly not logically independent. Additionally, because of dummy coding, $\beta_{h}$ and $\beta_{c}$ are defined by their difference from $\alpha$ (the population density of omnivores). 



## Notation for multilevel models

To allow information about one trophic level to be shared with the other trophic levels, let's reframe this model into a varying-intercept. Because this is our first time writing out a multilevel model, let's first define some terms and notation. The style of notation presented here is based on [Gelman and Hill](https://www.cambridge.org/core/books/data-analysis-using-regression-and-multilevelhierarchical-models/32A29531C7FD730C3A68951A17C9D983) and [BDA3](http://www.stat.columbia.edu/~gelman/book/), which is used widely and is used in the `brms` documentation.

Here's a summary the notation we've been using so far for our regression models.

- Observations $i = 1, \ldots, n$ where an observation is the smallest unit of measurement (e.g. species in the PanTHERIA dataset).
- Outcome measurement $y = (y_{1}, \ldots, y_{n})$. These are the values being modeled (e.g. species population density).
- Regression predictors are either vectors $x$ or $n \times k$ matrix $X$. Unless the intercept is written out explicitly, the [first column of $X$ is all 1's]($matrix-notation).
- For each obsevation $i$, its row-vector of predictors is $X_{i}$.
- For each predictor $k$, the $(k + 1)^{st}$ column of $X$ as $X_{(k)}$ (assuming that the first column of $X$ is a columns of 1's). 
- Coefficients are sometimes written as a vector $\beta$ and sometimes individually as $\alpha$ and one or more $\beta$-s. 
- Any information about the unit labels $i$ should be coded in the regression inputs. For example, if $i = 1, \ldots, n$ are in temporal order, we should create a time variable $t_{i}$ and possibly include it in $X$.

As we introduce multilevel models, we also need to introduce some new notational conventions.

- Observations belong to a group $j = 1, \ldots, J$. This is for single level groupings (e.g. specimens of a speices).
- For a second grouping you can use $g = 1, \ldots, G$ to indicate those memberships. You can substitute other letters if you prefer, but try to avoid overloading you letters (e.g. if $k$ is the number of predictors, don't use $k$ as a grouping). 
- Indices $j[i]$ represent group membership ("$i$ belongs to group $j$").
- Group-level predictors are represented by $u$ if there is only one and by a matrix $U$ with $J$ rows if there are multiple. 
- Group-level regression coeffcients are typically labeled $\gamma$.
- $\sigma_{y}$ is the data-level standard devaition and $\sigma_{\alpha}$, $\sigma_{\beta}$, and so on, are for group-level standard deviations.

These conventions will get us through this lesson. As more complicated situations arise, we'll introduce additional notational conventions.


## From categorical predictors to varying-intercept

Now that we've established some ground rules, we can update our previous model with a multistate categorical predictor dummy coded to a varying-intercept model with that categorical predictor as the grouping factor. 

$$
\begin{align}
y_{i} &= \text{Normal}(\alpha_{j[i]}, \sigma) \\
\alpha_{j} &\sim \text{Normal}(\mu_{\alpha}, \sigma_{\alpha}) \\
\mu_{\alpha} &\sim \text{Normal}(0, 1) \\
\sigma_{\alpha} &\sim \text{Cauchy}^{+}(5) \\
\sigma &\sim \text{Cauchy}^{+}(5) \\
\end{align}
$$

Let's parse out this model.

$\alpha_{j[i]}$ is the intercept the group $j$ that species $i$ belongs to. The prior for $\alpha_{j}$ is a Normal distribution that has defined parameters instead of our normally chosen constants. These (hyper)parameters also have their own (hyper)priors.




```{r multilevel_example}
# do i use live data or do i do this by simulation?


```



A parameter for each state as well as a mean and sd for the population. Every observation updates all of these parameters. If the population is highly variable, then the prior is flat and uninformative, which means that individual states have very little to do with each other. if the population contains little variation, then the prior is narrow and highly informative -- an observation about 1 state will have a big impact on the estimates of of another state.







multilevel == hierachical == mixed effects


shrinkage


pooling

- complete
- none
- partial




the first step of multilevel modeling is to set up a regression with varying coefficients; the second step is to set up a regression model for the coefficients themselves.






ARM: with grouped data, a regression that includes indicators for groups is called a varying-intercept model because it can be interepreted as a model with a different intercept for each group.






```{r panteria_data}

pantheria <- read_tsv(here('data', 'PanTHERIA_1-0_WR05_Aug2008.txt'), 
                      na = '-999.00') %>%
  clean_names() %>% 
  rename(order = msw05_order,
         family = msw05_family,
         genus = msw05_genus,
         species = msw05_species,
         binomial = msw05_binomial) %>%
  mutate(mass_log = log(x5_1_adult_body_mass_g),
         range_group_log = log(x22_1_home_range_km2),
         range_indiv_log = log(x22_2_home_range_indiv_km2),
         density_log = log(x21_1_population_density_n_km2),
         activity_cycle = case_when(x1_1_activity_cycle == 1 ~ 'nocturnal',
                                    x1_1_activity_cycle == 2 ~ 'mixed',
                                    x1_1_activity_cycle == 3 ~ 'diurnal'),
         trophic_level = case_when(x6_2_trophic_level == 1 ~ 'herbivore',
                                   x6_2_trophic_level == 2 ~ 'omnivore',
                                   x6_2_trophic_level == 3 ~ 'carnivore')) %>%
  drop_na(density_log, mass_log, trophic_level, order, family, genus) %>%
  mutate(mass_log_stan = (mass_log - mean(mass_log)) / (2 * sd(mass_log)),
         trophic_level = fct_infreq(trophic_level))

```


```{r pantheria_family, cache = TRUE, message = FALSE, results = 'hide'}

m_1 <- pantheria %>%
  brm(data = .,
      family = gaussian(),
      formula = bf(density_log ~ 1 + mass_log_stan + trophic_level + (1 | order)),
      prior = c(prior(normal(0, 10), class = 'Intercept'),
                prior(normal(0, 5), class = 'b'),
                prior(normal(-1, 5), class = 'b', coef = 'mass_log_stan'),
                prior(cauchy(0, 5), class = 'sigma'),
                prior(cauchy(0, 1), class = 'sd', group = 'order')),
      iter = 2000,
      warmup = 1000,
      chains = 4,
      cores = 4,
      refresh = 0)

```



Repeated measurements





