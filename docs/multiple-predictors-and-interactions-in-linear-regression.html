<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>5 Multiple predictors and interactions in linear regression | Analytical Paleobiology</title>
  <meta name="description" content="An informal course on analytical paleobiology">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="5 Multiple predictors and interactions in linear regression | Analytical Paleobiology" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="An informal course on analytical paleobiology" />
  <meta name="github-repo" content="psmits/paleo_book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5 Multiple predictors and interactions in linear regression | Analytical Paleobiology" />
  <meta name="twitter:site" content="@PeterDSmits" />
  <meta name="twitter:description" content="An informal course on analytical paleobiology" />
  

<meta name="author" content="Peter D Smits">


<meta name="date" content="2019-03-19">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="reg-continue.html">
<link rel="next" href="logistic-regression.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="...">Short-Course on Analytical Paleobiology</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="managing-and-processing-data-from-the-paleobiology-database.html"><a href="managing-and-processing-data-from-the-paleobiology-database.html"><i class="fa fa-check"></i><b>1</b> Managing and Processing Data From the Paleobiology Database</a><ul>
<li class="chapter" data-level="1.1" data-path="managing-and-processing-data-from-the-paleobiology-database.html"><a href="managing-and-processing-data-from-the-paleobiology-database.html#objectives"><i class="fa fa-check"></i><b>1.1</b> Objectives</a></li>
<li class="chapter" data-level="1.2" data-path="managing-and-processing-data-from-the-paleobiology-database.html"><a href="managing-and-processing-data-from-the-paleobiology-database.html#project-reading"><i class="fa fa-check"></i><b>1.2</b> Reading</a></li>
<li class="chapter" data-level="1.3" data-path="managing-and-processing-data-from-the-paleobiology-database.html"><a href="managing-and-processing-data-from-the-paleobiology-database.html#introduction"><i class="fa fa-check"></i><b>1.3</b> Introduction</a></li>
<li class="chapter" data-level="1.4" data-path="managing-and-processing-data-from-the-paleobiology-database.html"><a href="managing-and-processing-data-from-the-paleobiology-database.html#getting-data"><i class="fa fa-check"></i><b>1.4</b> Getting data</a></li>
<li class="chapter" data-level="1.5" data-path="managing-and-processing-data-from-the-paleobiology-database.html"><a href="managing-and-processing-data-from-the-paleobiology-database.html#processing-data"><i class="fa fa-check"></i><b>1.5</b> Processing data</a></li>
<li class="chapter" data-level="1.6" data-path="managing-and-processing-data-from-the-paleobiology-database.html"><a href="managing-and-processing-data-from-the-paleobiology-database.html#binning-observations"><i class="fa fa-check"></i><b>1.6</b> Binning observations</a></li>
<li class="chapter" data-level="1.7" data-path="managing-and-processing-data-from-the-paleobiology-database.html"><a href="managing-and-processing-data-from-the-paleobiology-database.html#sharing-data"><i class="fa fa-check"></i><b>1.7</b> Sharing data</a></li>
<li class="chapter" data-level="1.8" data-path="managing-and-processing-data-from-the-paleobiology-database.html"><a href="managing-and-processing-data-from-the-paleobiology-database.html#summary"><i class="fa fa-check"></i><b>1.8</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html"><i class="fa fa-check"></i><b>2</b> Introduction to Bayesian data analysis</a><ul>
<li class="chapter" data-level="2.1" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#objectives-1"><i class="fa fa-check"></i><b>2.1</b> Objectives</a></li>
<li class="chapter" data-level="2.2" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#reading"><i class="fa fa-check"></i><b>2.2</b> Reading</a></li>
<li class="chapter" data-level="2.3" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#learning-from-data"><i class="fa fa-check"></i><b>2.3</b> Learning from data</a><ul>
<li class="chapter" data-level="2.3.1" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#counting-and-plausibility"><i class="fa fa-check"></i><b>2.3.1</b> Counting and plausibility</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#globe-example"><i class="fa fa-check"></i><b>2.4</b> Building a model</a><ul>
<li class="chapter" data-level="2.4.1" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#a-data-story"><i class="fa fa-check"></i><b>2.4.1</b> A data story</a></li>
<li class="chapter" data-level="2.4.2" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#bayesian-updating"><i class="fa fa-check"></i><b>2.4.2</b> Bayesian updating</a></li>
<li class="chapter" data-level="2.4.3" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#evaluate"><i class="fa fa-check"></i><b>2.4.3</b> Evaluate</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#terms-and-theory"><i class="fa fa-check"></i><b>2.5</b> Terms and theory</a></li>
<li class="chapter" data-level="2.6" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#bayes-theorem"><i class="fa fa-check"></i><b>2.6</b> Bayes’ Theorem</a></li>
<li class="chapter" data-level="2.7" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#but-how-does-it-work"><i class="fa fa-check"></i><b>2.7</b> But how does it <em>work</em>?</a><ul>
<li class="chapter" data-level="2.7.1" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#grid-approximation"><i class="fa fa-check"></i><b>2.7.1</b> Grid approximation</a></li>
<li class="chapter" data-level="2.7.2" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#markov-chain-monte-carlo"><i class="fa fa-check"></i><b>2.7.2</b> Markov chain Monte Carlo</a></li>
<li class="chapter" data-level="2.7.3" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#aside-on-interpreting-probabilities"><i class="fa fa-check"></i><b>2.7.3</b> Aside on Interpreting Probabilities</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#working-with-samples"><i class="fa fa-check"></i><b>2.8</b> Working with samples</a><ul>
<li class="chapter" data-level="2.8.1" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#intervals-of-defined-boundaries"><i class="fa fa-check"></i><b>2.8.1</b> Intervals of defined boundaries</a></li>
<li class="chapter" data-level="2.8.2" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#intervals-of-defined-mass"><i class="fa fa-check"></i><b>2.8.2</b> Intervals of defined mass</a></li>
<li class="chapter" data-level="2.8.3" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#point-estimates"><i class="fa fa-check"></i><b>2.8.3</b> Point estimates</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#summary-1"><i class="fa fa-check"></i><b>2.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="reg-intro.html"><a href="reg-intro.html"><i class="fa fa-check"></i><b>3</b> Introduction to linear regression</a><ul>
<li class="chapter" data-level="3.1" data-path="reg-intro.html"><a href="reg-intro.html#objectives-2"><i class="fa fa-check"></i><b>3.1</b> Objectives</a></li>
<li class="chapter" data-level="3.2" data-path="reg-intro.html"><a href="reg-intro.html#reading-1"><i class="fa fa-check"></i><b>3.2</b> Reading</a></li>
<li class="chapter" data-level="3.3" data-path="reg-intro.html"><a href="reg-intro.html#linear-regression"><i class="fa fa-check"></i><b>3.3</b> Linear regression</a><ul>
<li class="chapter" data-level="3.3.1" data-path="reg-intro.html"><a href="reg-intro.html#talking-about-models"><i class="fa fa-check"></i><b>3.3.1</b> Talking about models</a></li>
<li class="chapter" data-level="3.3.2" data-path="reg-intro.html"><a href="reg-intro.html#growing-a-regression-model"><i class="fa fa-check"></i><b>3.3.2</b> Growing a regression model</a></li>
<li class="chapter" data-level="3.3.3" data-path="reg-intro.html"><a href="reg-intro.html#sampling-from-the-model"><i class="fa fa-check"></i><b>3.3.3</b> Sampling from the model</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="reg-intro.html"><a href="reg-intro.html#adding-a-predictor-to-the-mix"><i class="fa fa-check"></i><b>3.4</b> Adding a predictor to the mix</a><ul>
<li class="chapter" data-level="3.4.1" data-path="reg-intro.html"><a href="reg-intro.html#aside-dummy-coding"><i class="fa fa-check"></i><b>3.4.1</b> Aside: Dummy coding</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="reg-intro.html"><a href="reg-intro.html#interpreting-the-model-fit"><i class="fa fa-check"></i><b>3.5</b> Interpreting the model fit</a><ul>
<li class="chapter" data-level="3.5.1" data-path="reg-intro.html"><a href="reg-intro.html#linear-predictor"><i class="fa fa-check"></i><b>3.5.1</b> Linear predictor</a></li>
<li class="chapter" data-level="3.5.2" data-path="reg-intro.html"><a href="reg-intro.html#posterior-prediction"><i class="fa fa-check"></i><b>3.5.2</b> Posterior prediction</a></li>
<li class="chapter" data-level="3.5.3" data-path="reg-intro.html"><a href="reg-intro.html#posterior-predictive-tests"><i class="fa fa-check"></i><b>3.5.3</b> Posterior predictive tests</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="reg-intro.html"><a href="reg-intro.html#summary-2"><i class="fa fa-check"></i><b>3.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="reg-continue.html"><a href="reg-continue.html"><i class="fa fa-check"></i><b>4</b> Continuing with regression with continuous predictors</a><ul>
<li class="chapter" data-level="4.1" data-path="reg-continue.html"><a href="reg-continue.html#objectives-3"><i class="fa fa-check"></i><b>4.1</b> Objectives</a></li>
<li class="chapter" data-level="4.2" data-path="reg-continue.html"><a href="reg-continue.html#reading-2"><i class="fa fa-check"></i><b>4.2</b> Reading</a></li>
<li class="chapter" data-level="4.3" data-path="reg-continue.html"><a href="reg-continue.html#our-first-example"><i class="fa fa-check"></i><b>4.3</b> Our first example</a></li>
<li class="chapter" data-level="4.4" data-path="reg-continue.html"><a href="reg-continue.html#a-single-continuous-predictor"><i class="fa fa-check"></i><b>4.4</b> A single continuous predictor</a><ul>
<li class="chapter" data-level="4.4.1" data-path="reg-continue.html"><a href="reg-continue.html#aside-centering"><i class="fa fa-check"></i><b>4.4.1</b> Aside: Centering</a></li>
<li class="chapter" data-level="4.4.2" data-path="reg-continue.html"><a href="reg-continue.html#checking-model-fit"><i class="fa fa-check"></i><b>4.4.2</b> Checking model fit</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="reg-continue.html"><a href="reg-continue.html#summary-3"><i class="fa fa-check"></i><b>4.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="multiple-predictors-and-interactions-in-linear-regression.html"><a href="multiple-predictors-and-interactions-in-linear-regression.html"><i class="fa fa-check"></i><b>5</b> Multiple predictors and interactions in linear regression</a><ul>
<li class="chapter" data-level="5.1" data-path="multiple-predictors-and-interactions-in-linear-regression.html"><a href="multiple-predictors-and-interactions-in-linear-regression.html#objectives-4"><i class="fa fa-check"></i><b>5.1</b> Objectives</a></li>
<li class="chapter" data-level="5.2" data-path="multiple-predictors-and-interactions-in-linear-regression.html"><a href="multiple-predictors-and-interactions-in-linear-regression.html#reading-3"><i class="fa fa-check"></i><b>5.2</b> Reading</a></li>
<li class="chapter" data-level="5.3" data-path="multiple-predictors-and-interactions-in-linear-regression.html"><a href="multiple-predictors-and-interactions-in-linear-regression.html#more-than-one-predictor"><i class="fa fa-check"></i><b>5.3</b> More than one predictor</a><ul>
<li class="chapter" data-level="5.3.1" data-path="multiple-predictors-and-interactions-in-linear-regression.html"><a href="multiple-predictors-and-interactions-in-linear-regression.html#dummy"><i class="fa fa-check"></i><b>5.3.1</b> Categorical predictor</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="multiple-predictors-and-interactions-in-linear-regression.html"><a href="multiple-predictors-and-interactions-in-linear-regression.html#defining-our-model"><i class="fa fa-check"></i><b>5.4</b> Defining our model</a></li>
<li class="chapter" data-level="5.5" data-path="multiple-predictors-and-interactions-in-linear-regression.html"><a href="multiple-predictors-and-interactions-in-linear-regression.html#fitting-model-in-brms"><i class="fa fa-check"></i><b>5.5</b> Fitting model in <code>brms</code></a></li>
<li class="chapter" data-level="5.6" data-path="multiple-predictors-and-interactions-in-linear-regression.html"><a href="multiple-predictors-and-interactions-in-linear-regression.html#aside-standardizing"><i class="fa fa-check"></i><b>5.6</b> Aside: Standardizing</a></li>
<li class="chapter" data-level="5.7" data-path="multiple-predictors-and-interactions-in-linear-regression.html"><a href="multiple-predictors-and-interactions-in-linear-regression.html#checking-model-fit-1"><i class="fa fa-check"></i><b>5.7</b> Checking model fit</a></li>
<li class="chapter" data-level="5.8" data-path="multiple-predictors-and-interactions-in-linear-regression.html"><a href="multiple-predictors-and-interactions-in-linear-regression.html#matrix-notation"><i class="fa fa-check"></i><b>5.8</b> Aside: Matrix Notation</a></li>
<li class="chapter" data-level="5.9" data-path="multiple-predictors-and-interactions-in-linear-regression.html"><a href="multiple-predictors-and-interactions-in-linear-regression.html#summary-4"><i class="fa fa-check"></i><b>5.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>6</b> Logistic regression</a><ul>
<li class="chapter" data-level="6.1" data-path="logistic-regression.html"><a href="logistic-regression.html#objectives-5"><i class="fa fa-check"></i><b>6.1</b> Objectives</a></li>
<li class="chapter" data-level="6.2" data-path="logistic-regression.html"><a href="logistic-regression.html#introduction-1"><i class="fa fa-check"></i><b>6.2</b> Introduction</a></li>
<li class="chapter" data-level="6.3" data-path="logistic-regression.html"><a href="logistic-regression.html#foram-coiling"><i class="fa fa-check"></i><b>6.3</b> Foram coiling</a></li>
<li class="chapter" data-level="6.4" data-path="logistic-regression.html"><a href="logistic-regression.html#writing-out-a-model"><i class="fa fa-check"></i><b>6.4</b> Writing out a model</a><ul>
<li class="chapter" data-level="6.4.1" data-path="logistic-regression.html"><a href="logistic-regression.html#interpreting-logistic-regression-coefficients"><i class="fa fa-check"></i><b>6.4.1</b> Interpreting logistic regression coefficients</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="logistic-regression.html"><a href="logistic-regression.html#odds-ratios"><i class="fa fa-check"></i><b>6.5</b> Odds ratios</a></li>
<li class="chapter" data-level="6.6" data-path="logistic-regression.html"><a href="logistic-regression.html#priors-for-our-model"><i class="fa fa-check"></i><b>6.6</b> Priors for our model</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="poisson-regression-and-others-glms.html"><a href="poisson-regression-and-others-glms.html"><i class="fa fa-check"></i><b>7</b> Poisson regression and others GLMs</a><ul>
<li class="chapter" data-level="7.1" data-path="poisson-regression-and-others-glms.html"><a href="poisson-regression-and-others-glms.html#outline"><i class="fa fa-check"></i><b>7.1</b> Outline</a></li>
<li class="chapter" data-level="7.2" data-path="poisson-regression-and-others-glms.html"><a href="poisson-regression-and-others-glms.html#poisson-distribution"><i class="fa fa-check"></i><b>7.2</b> Poisson distribution</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="varying-intercepts.html"><a href="varying-intercepts.html"><i class="fa fa-check"></i><b>8</b> Varying-intercept(s)</a><ul>
<li class="chapter" data-level="8.1" data-path="varying-intercepts.html"><a href="varying-intercepts.html#objectives-6"><i class="fa fa-check"></i><b>8.1</b> Objectives</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="varying-slopes.html"><a href="varying-slopes.html"><i class="fa fa-check"></i><b>9</b> Varying slope(s)</a></li>
<li class="chapter" data-level="10" data-path="varying-slopes-and-intercepts.html"><a href="varying-slopes-and-intercepts.html"><i class="fa fa-check"></i><b>10</b> Varying slopes and intercepts</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown">
Proudly published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Analytical Paleobiology</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="multiple-predictors-and-interactions-in-linear-regression" class="section level1">
<h1><span class="header-section-number">5</span> Multiple predictors and interactions in linear regression</h1>
<div id="objectives-4" class="section level2">
<h2><span class="header-section-number">5.1</span> Objectives</h2>
<ul>
<li>Interpret regression models with a categorical predictor that has more than two levels.</li>
<li>Learn to interpret regression models with more than one predictor.</li>
<li>Introduce statistical interactions in regression models.</li>
<li>Cover strategies for visualizing multivariate regression models.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(pacman)

<span class="kw">p_load</span>(tidyverse, here, janitor, purrr, viridis, brms, tidybayes, bayesplot,
       modelr, forcats)

<span class="kw">theme_set</span>(<span class="kw">theme_bw</span>())</code></pre></div>
</div>
<div id="reading-3" class="section level2">
<h2><span class="header-section-number">5.2</span> Reading</h2>
<p>The following materials are recommended pre-readings before starting this tutorial.</p>
<ul>
<li>Chapter 5 “Multivariate Linear Models” from <a href="https://xcelab.net/rm/statistical-rethinking/"><strong>Statistical Rethinking</strong> by Richard McElreath</a>.</li>
<li>OPTIONAL Chapter 3 “Linear regression: the basics” from <a href="https://www.cambridge.org/core/books/data-analysis-using-regression-and-multilevelhierarchical-models/32A29531C7FD730C3A68951A17C9D983"><strong>Data Analysis Using Regression and Multilevel/Hierarchical Models</strong> by Gelman and Hill</a>.</li>
<li>OPTIONAL Chapter 4 “Linear regression: before and after fitting the model” from <a href="https://www.cambridge.org/core/books/data-analysis-using-regression-and-multilevelhierarchical-models/32A29531C7FD730C3A68951A17C9D983"><strong>Data Analysis Using Regression and Multilevel/Hierarchical Models</strong> by Gelman and Hill</a>.</li>
</ul>
</div>
<div id="more-than-one-predictor" class="section level2">
<h2><span class="header-section-number">5.3</span> More than one predictor</h2>
<p>Correlation between variables is very common in nature. In large datasets, all pairs of variables have a statistically discernible non-zero correlation. We should never be surprised to find that two variables are correlated. But simple correlation tells us nothing of mechanism – the “biology” of the system. We need tools to distinguist between mere association from evidence of causation. This is where multivariate regression (regression with more than one predictor variable) comes into play.</p>
<p>The three general reasons for using a multivariate model are:</p>
<ul>
<li><p><strong>Confounds</strong> or variables that may be correlated with variable of interest. Confounds can easily hide important variables or produce false signals. Check out <a href="https://en.wikipedia.org/wiki/Simpson%27s_paradox">Simpson’s Paradox</a> for an example of how a relationship can be reversed in the presence of a confound.</p></li>
<li><p><strong>Multiple causation</strong>. Reality is rarely simple, to the point that we can safely assume complexity. By considering that complexity, we can improve our understanding. Additionally, when causation is multiple one cause can hide another unless they are considered simultaneously.</p></li>
<li><p><strong>Interactions</strong>. Even in the absence of correlation, effects of two or more variables might depend on each other. An example would be plant growth as a function of light and water – both are needed and only having one yields no benefit. In order to make effective inference about one variable, we need to consider the others as well.</p></li>
</ul>
<p>So far all of the linear regression models we have encountered have either been intercept-only or with a single predictor. For this lesson we’re going to continue our focus on three variables from the PanTHERIA dataset: population density, body size, and trophic level. Population density, measured as the number of individuals per square-kilometer, is our variable of interest – we want to define a model which describes how population density varies between mammal species. We have previously investigated body size as a predictor of population density, but the posterior predictive analysis of our model of population density with only body mass as a predictor demonstrates that this model does not adequately describe the data. We were able to do this by asking if our model is able to describe differences in the data that we know about but that our model does not (e.g. trophic level).</p>
<p>We’re going to be using the PanTHERIA dataset like we did in the <a href="reg-continue.html#reg-continue">previous lesson</a>. Just like last time, here is a quick clean up of the dataset before we do anything “principled.”</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pantheria &lt;-<span class="st"> </span><span class="kw">read_tsv</span>(<span class="kw">here</span>(<span class="st">&#39;data&#39;</span>, <span class="st">&#39;PanTHERIA_1-0_WR05_Aug2008.txt&#39;</span>), 
                      <span class="dt">na =</span> <span class="st">&#39;-999.00&#39;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">clean_names</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">mass_log =</span> <span class="kw">log</span>(x5_<span class="dv">1</span>_adult_body_mass_g),
         <span class="dt">range_group_log =</span> <span class="kw">log</span>(x22_<span class="dv">1</span>_home_range_km2),
         <span class="dt">range_indiv_log =</span> <span class="kw">log</span>(x22_<span class="dv">2</span>_home_range_indiv_km2),
         <span class="dt">density_log =</span> <span class="kw">log</span>(x21_<span class="dv">1</span>_population_density_n_km2),
         <span class="dt">activity_cycle =</span> <span class="kw">case_when</span>(x1_<span class="dv">1</span>_activity_cycle <span class="op">==</span><span class="st"> </span><span class="dv">1</span> <span class="op">~</span><span class="st"> &#39;nocturnal&#39;</span>,
                                    x1_<span class="dv">1</span>_activity_cycle <span class="op">==</span><span class="st"> </span><span class="dv">2</span> <span class="op">~</span><span class="st"> &#39;mixed&#39;</span>,
                                    x1_<span class="dv">1</span>_activity_cycle <span class="op">==</span><span class="st"> </span><span class="dv">3</span> <span class="op">~</span><span class="st"> &#39;diurnal&#39;</span>),
         <span class="dt">trophic_level =</span> <span class="kw">case_when</span>(x6_<span class="dv">2</span>_trophic_level <span class="op">==</span><span class="st"> </span><span class="dv">1</span> <span class="op">~</span><span class="st"> &#39;herbivore&#39;</span>,
                                   x6_<span class="dv">2</span>_trophic_level <span class="op">==</span><span class="st"> </span><span class="dv">2</span> <span class="op">~</span><span class="st"> &#39;omnivore&#39;</span>,
                                   x6_<span class="dv">2</span>_trophic_level <span class="op">==</span><span class="st"> </span><span class="dv">3</span> <span class="op">~</span><span class="st"> &#39;carnivore&#39;</span>))</code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   .default = col_double(),
##   MSW05_Order = col_character(),
##   MSW05_Family = col_character(),
##   MSW05_Genus = col_character(),
##   MSW05_Species = col_character(),
##   MSW05_Binomial = col_character(),
##   References = col_character()
## )</code></pre>
<pre><code>## See spec(...) for full column specifications.</code></pre>
<div id="dummy" class="section level3">
<h3><span class="header-section-number">5.3.1</span> Categorical predictor</h3>
<p>Trophic level is a categorical predictor with three levels. The previous categorical predictor we dealt with (Bivalve versus Brachiopod) was binary which made it very easy to interpret. In that lesson I briefly introduced the idea of dummy coding and demonstrated how that would work with a three level categorical variable. I’m going to reiterate and expand on that demonstration here.</p>
<p><code>brm</code>, and R in general, will automatically translate categorical predictors like our <code>trophic_level</code> variable into what’s called <em>dummy coding</em>.</p>
<p>When we dummy code a categorical variable what we are doing is turning one variable with <span class="math inline">\(k\)</span> states into <span class="math inline">\(k - 1\)</span> binary variables. One state of the categorical variable is considered the “baseline” or the default condition for any observation. The other <span class="math inline">\(k - 1\)</span> binary variables then describe if the observation is different from the default – these are called contrasts. The standard behavior for this in R is that the first state, alphabetically, is made the baseline. Here is this in action:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(pantheria <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">drop_na</span>(trophic_level) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">model_matrix</span>(<span class="op">~</span><span class="st"> </span>trophic_level))</code></pre></div>
<pre><code>## # A tibble: 2,161 x 3
##    `(Intercept)` trophic_levelherbivore trophic_levelomnivore
##            &lt;dbl&gt;                  &lt;dbl&gt;                 &lt;dbl&gt;
##  1             1                      1                     0
##  2             1                      0                     1
##  3             1                      0                     1
##  4             1                      0                     0
##  5             1                      0                     0
##  6             1                      1                     0
##  7             1                      1                     0
##  8             1                      1                     0
##  9             1                      0                     1
## 10             1                      0                     1
## # … with 2,151 more rows</code></pre>
<p>The <code>model_matrix()</code> function returns a tibble with <span class="math inline">\(k\)</span> columns. Take a closer look at the column names. First, focus on the second and third columns. Each title is the variable name (<code>trophic_level</code>) combined with one of the levels (e.g. <code>trophic_levelherbivore</code>). One of the factor’s levels, carnivore, is not named as one of the columns, instead that level is subsumed in the <code>(Intercept)</code> column.</p>
<p>The default state of any observation is this “carnivore.” A 0 in the <code>trophic_levelherbivore</code> or <code>trophic_levelomnivore</code> columns means that the observation is not an herbivore or omnivore, respectively. If there is a 1 in the herbivore or omnivore column that means that observation is an herbivore or omnivore and not a carnivore – hence why the <span class="math inline">\(k - 1\)</span> binary variables are called contrasts (with respect to the default condition/intercept). Importantly, an observation cannot/should not have a 1 in more than one of the <span class="math inline">\(k - 1\)</span> binary variables associated with a single categorical predictor.</p>
<p>Let’s see what happens when we suppress the intercept using R’s <a href="https://stat.ethz.ch/R-manual/R-devel/library/stats/html/formula.html">formula syntax</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(pantheria <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">drop_na</span>(trophic_level) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">model_matrix</span>(<span class="op">~</span><span class="st"> </span><span class="dv">-1</span> <span class="op">+</span><span class="st"> </span>trophic_level))</code></pre></div>
<pre><code>## # A tibble: 2,161 x 3
##    trophic_levelcarnivore trophic_levelherbivore trophic_levelomnivore
##                     &lt;dbl&gt;                  &lt;dbl&gt;                 &lt;dbl&gt;
##  1                      0                      1                     0
##  2                      0                      0                     1
##  3                      0                      0                     1
##  4                      1                      0                     0
##  5                      1                      0                     0
##  6                      0                      1                     0
##  7                      0                      1                     0
##  8                      0                      1                     0
##  9                      0                      0                     1
## 10                      0                      0                     1
## # … with 2,151 more rows</code></pre>
<p>By suppressing the intercept in our model matrix, we’ve dramatically changed the first column of our tibble. Instead of being labeled <code>(Intercept)</code> and being a column of only 1s, we have a column named <code>trophic_levelcarnivora</code> which is a binary variable indicating if an observation is a carnivore or not.</p>
<p>I do not recommend suppressing the intercept when developing a model, especially if you are generating your contrasts independent of the model formula (e.g. when using <code>brm()</code>), and extra especially if you have more predictors in your model than just the categorical variable being coded out. If you are not careful, you might end up with the equivalent of two intercepts which causes a model to be completely undefined and useless.</p>
<p>As as been discussed before, R tacitly converts our categorical variables (e.g. variables where our observations are character data) into dummy coding. While this is convenient, it can lead to confusion if you aren’t super familiar with categorical variables. For example, I once had a colleague ask, “How are there 5 parameters when we only have 1 predictor in our linear regression (they expected three)?”</p>
<p>Something I like to do is make the most common or most general class be the intercept. This adds a bit of logic to the contrasts, as they are now “in contrast” to the most common state. The most common class in <code>trophic_level</code> is “herbivore”. To change which class becomes the intercept, we need to manipulate the R structure of <code>trophic_level</code>. I’m choosing to do this using functions from the <code>forcats</code> package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(pantheria <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">drop_na</span>(trophic_level) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">trophic_level =</span> <span class="kw">fct_infreq</span>(trophic_level)) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># reorder by frequency</span>
<span class="st">  </span><span class="kw">model_matrix</span>(<span class="op">~</span><span class="st"> </span>trophic_level))</code></pre></div>
<pre><code>## # A tibble: 2,161 x 3
##    `(Intercept)` trophic_levelomnivore trophic_levelcarnivore
##            &lt;dbl&gt;                 &lt;dbl&gt;                  &lt;dbl&gt;
##  1             1                     0                      0
##  2             1                     1                      0
##  3             1                     1                      0
##  4             1                     0                      1
##  5             1                     0                      1
##  6             1                     0                      0
##  7             1                     0                      0
##  8             1                     0                      0
##  9             1                     1                      0
## 10             1                     1                      0
## # … with 2,151 more rows</code></pre>
<p>By controlling which of the classes from our categorical variable is considered the intercept, we can make inference easier. Carnivores are relatively rare in our dataset, so having them as the “default” condition for our model is a bit confusing – most of our observations would be “exceptions” or “in contrast to” our default. By having herbivores act as are default, we inherently are describing more parts of our data before looking at the contrasts.</p>
<p>There are <a href="https://stats.idre.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/">many other strategies for encoding categorical variables</a>, but dummy coding is by far the most common – it helps that it is the R default.</p>
</div>
</div>
<div id="defining-our-model" class="section level2">
<h2><span class="header-section-number">5.4</span> Defining our model</h2>
<p>Now that we have refreshed our understanding of how categorical covariates are handled in a regression model, let’s write out a model describing how <code>density_log</code> varies as a linear function of our <code>trophic_level</code> categorical predictor and the <code>mass_log</code> continuous covariate. As always, let’s write out our model in statistical notation before implementing it in <code>brms</code>.</p>
<p>Multivariable regression models add more parameters and variables to the defintion of the mean of the Normal distribution, <span class="math inline">\(\mu_{i}\)</span>. For each predictor we will essentially do three things:</p>
<ol style="list-style-type: decimal">
<li>Nominate the predictor variable of interest.</li>
<li>Create a parameter that will measure the association between that variable and the outcome.</li>
<li>Multiply the parameter by the variable and add that term to the linear model.</li>
</ol>
<p>To demonstrate this, I’m going to be a bit more formal in defining our statistical model than <a href="reg-continue.html#reg-continue">before</a> because it is good practice and because this model is more complicated than the ones we have seen before.</p>
<p>We have <span class="math inline">\(N\)</span> total observations (species) in our dataset. We can define our response variable, <code>density_log</code>, as <span class="math inline">\(y_{i}\)</span> where <span class="math inline">\(i\)</span> index which species that measure is from and <span class="math inline">\(i = 1, 2, \ldots, N\)</span>. We have our two predictor variables <code>mass_log</code> and <code>trophic_level</code> which are continuous and categorical, respectively. Our first predictor is the continuous <code>mass_log</code> of each observation – let’s call this variable <span class="math inline">\(x_{i}\)</span> where <span class="math inline">\(i = 1, 2, \ldots, N\)</span>. Our second variable is the categorical <code>trophic_level</code> which has three classes: carnivore, herbivore, omnivore. As discussed before, we are going to rewrite this variable as a set of <span class="math inline">\(k - 1\)</span> contrasts where <span class="math inline">\(k\)</span> is the number of levels in the variable (i.e. three). Let’s name herbivore to be the baseline, with carnivore and omnivore being the contrasts. We can define these two binary predictors as <span class="math inline">\(c_{i}\)</span> and <span class="math inline">\(o_{i}\)</span>, respectively.</p>
<p>This covers all of our data. Now lets define the parameters that describe our the bits of our data are related. We need to define a regression model describing how the expected value of <span class="math inline">\(y\)</span> varies as a function of <span class="math inline">\(x\)</span>, <span class="math inline">\(c\)</span>, and <span class="math inline">\(o\)</span>.</p>
<p>Let’s assume a Normal distribution is a suitable descriptor of population density, the core assumption of linear regression. We can the define mean and standard deviation of this distribution as <span class="math inline">\(\mu_{i}\)</span> and <span class="math inline">\(\sigma\)</span>. <span class="math inline">\(\mu\)</span> is indexed by observation <span class="math inline">\(i\)</span> where <span class="math inline">\(i = 1, 2, \ldots, N\)</span> because we are going to define it as a linear function of our predictors which vary for each of our <span class="math inline">\(N\)</span> observations. We then can define the linear function describing <span class="math inline">\(mu_{i}\)</span> as an additive relationship of each covariate multiplied by its own regression coefficient plus an intercept. Let’s identify the intercept as <span class="math inline">\(\alpha\)</span> and the three coefficients as <span class="math inline">\(\beta_{1}\)</span>, <span class="math inline">\(\beta_{2}\)</span>, and <span class="math inline">\(\beta_{3}\)</span>.</p>
<p>Now that we’ve defined all of our data terms and parameters, we need to define the remaining priors for the regression coefficients and standard deviation parameter. I’m going to stick with what the priors we used from our <a href="reg-continue.html#reg-continue">previous lesson</a>, with a slightly informative prior for the effect of body mass and general weakly informative priors for the other regression coefficients.</p>
<p><span class="math display">\[
\begin{align}
y_{i} &amp;\sim \text{Normal}(\mu_{i}, \sigma) \\
\mu_{i} &amp;= \alpha + \beta_{1} m_{i} + \beta_{2} o_{i} + \beta_{3} h_{i} \\
\alpha &amp;\sim \text{Normal}(0, 10) \\
\beta_{1} &amp;\sim \text{Normal}(-1, 5) \\
\beta_{2} &amp;\sim \text{Normal}(0, 5) \\
\beta_{3} &amp;\sim \text{Normal}(0, 5) \\
\sigma &amp;\sim \text{Cauchy}^{+}(0, 5) \\
\end{align}
\]</span></p>
<p>But how do we interpret a regression coefficient when we have more than one regression coefficient? The standard advice is to interpret an individual coefficient while assuming that all other predictors are held constant. The meaning of each regression coefficient is independent of the others because we are assuming the covariates are independent of one another – for example, that body size has noting to do with trophic level. Is this assumption correct? Probably not. Is it defensible? Possibly.</p>
</div>
<div id="fitting-model-in-brms" class="section level2">
<h2><span class="header-section-number">5.5</span> Fitting model in <code>brms</code></h2>
<p>Now that we’ve been able to write out our complete statistical model, we can not implement it in <code>brms</code>.</p>
<p>Our first task limiting our data to not include observations with missing values for our variables of interest. After that, we need to center our continuous predictor so that our intercept has a <a href="reg-continue.html#reg-continue">clean interpretation</a>.</p>
<p>After our data is prepared for analysis, we can then write our <code>brm()</code> call.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pantheria_fit &lt;-<span class="st"> </span>
<span class="st">  </span>pantheria <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">drop_na</span>(density_log, mass_log, trophic_level) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">mass_log_center =</span> mass_log <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(mass_log),
         <span class="dt">trophic_level =</span> <span class="kw">fct_infreq</span>(trophic_level))</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m_<span class="dv">1</span> &lt;-<span class="st"> </span>
<span class="st">  </span>pantheria_fit <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> .,
      <span class="dt">family =</span> <span class="kw">gaussian</span>(),
      <span class="dt">formula =</span> <span class="kw">bf</span>(density_log <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>mass_log_center <span class="op">+</span><span class="st"> </span>trophic_level),
      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> Intercept),
                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">5</span>), <span class="dt">class =</span> b),
                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">5</span>), <span class="dt">class =</span> b, <span class="dt">coef =</span> mass_log_center),
                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">5</span>), <span class="dt">class =</span> sigma)),
      <span class="dt">iter =</span> <span class="dv">2000</span>,
      <span class="dt">warmup =</span> <span class="dv">1000</span>,
      <span class="dt">chains =</span> <span class="dv">4</span>,
      <span class="dt">cores =</span> <span class="dv">4</span>,
      <span class="dt">refresh =</span> <span class="dv">0</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(m_<span class="dv">1</span>)</code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: density_log ~ 1 + mass_log_center + trophic_level 
##    Data: . (Number of observations: 746) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##                        Estimate Est.Error l-95% CI u-95% CI Eff.Sample
## Intercept                  3.15      0.10     2.95     3.35       4610
## mass_log_center           -0.82      0.02    -0.87    -0.78       4434
## trophic_levelherbivore     1.30      0.15     1.00     1.60       4493
## trophic_levelcarnivore    -1.31      0.21    -1.71    -0.92       4422
##                        Rhat
## Intercept              1.00
## mass_log_center        1.00
## trophic_levelherbivore 1.00
## trophic_levelcarnivore 1.00
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sigma     1.80      0.05     1.72     1.90       4410 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
<div id="aside-standardizing" class="section level2">
<h2><span class="header-section-number">5.6</span> Aside: Standardizing</h2>
<p>Remember, regression coefficients (e.g. <span class="math inline">\(\beta_{1}\)</span>) are interpreted as the expected change in <span class="math inline">\(y\)</span> per unit change in the predictor (e.g. <span class="math inline">\(m\)</span>). If our predictors are not on the same scale, it is “unfair” to compare them directly. For example, how can we compare the effect size of body mass versus being an herbivore on population density? While the regression coeffcient for being an herbivore (instead of an omnivore) has a greater magnitude than the coefficient for mass, but this is misleading because a complete difference in category to a 1-km<span class="math inline">\(^2\)</span> change in geographic range.</p>
<p>A natural solution to this problem is to standardize our predictors so that they are all on the same scale (having the same standard deviation). You might have heard of this as z-scores or something else – we will not be using this language.</p>
<p>To standardize our data, <a href="http://www.stat.columbia.edu/~gelman/arm/">Gelman and Hill</a> recommend scaling or predictors by dividing by 2 standard deviations so that “a 1-unit change in the rescaled predictor corresponds to a change from 1 standard deviation blow the mean, to 1 standard deviation above.”</p>
<p>But why 2 standard deviations and not 1? By dividing by 2 standard deviations we gain comparability between our continuous covariates and the binary predictors. For example, consider a simple binary variable <span class="math inline">\(x\)</span> where 0 and 1 occur with equal probability. The standard deviation of this variable is then <span class="math inline">\(\sqrt{0.5 \cdot 0.5} = 0.5\)</span>, which means the standardized variable, <span class="math inline">\((x - \mu_{x}) / (2 \sigma_{x})\)</span>, takes on the values <span class="math inline">\(\pm 0.5\)</span>, and its coefficient reflects comparisons between <span class="math inline">\(x = 0\)</span> and <span class="math inline">\(x = 1\)</span>. In contrast, dividing by 1 standard deviation means that the scaled variable takes on values <span class="math inline">\(\pm 1\)</span> and its coefficients correspond to half the difference between the two possible values of <span class="math inline">\(x\)</span>.</p>
<p><a href="http://www.stat.columbia.edu/~gelman/arm/">Gelman and Hill</a> also state that in complicated regression models with lots of predictors, we can leave our binary inputs as is and just transform our continuous predictors. In that case, the 2 standard deviation rule gives rough comparability in the coeffcieints. I generally just center and rescale my continuous covariates.</p>
<p>Our goal should be able to have meaningful interpretations for as many parameters as possible, especially regression coefficients. To ensure this, we should center and scale all continuous predictor variables before analysis. If these transformations aren’t done, than we can have difficulty interpreting our models intercept and can incorrectly and unfairly compare the estimates of our regression coefficients.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pantheria_fit2 &lt;-<span class="st"> </span>
<span class="st">  </span>pantheria <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">drop_na</span>(density_log, mass_log, trophic_level) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">mass_log_stan =</span> (mass_log <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(mass_log)) <span class="op">/</span><span class="st"> </span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(mass_log)),
         <span class="dt">trophic_level =</span> <span class="kw">fct_infreq</span>(trophic_level))</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m_<span class="dv">2</span> &lt;-<span class="st"> </span>
<span class="st">  </span>pantheria_fit2 <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> .,
      <span class="dt">family =</span> <span class="kw">gaussian</span>(),
      <span class="dt">formula =</span> <span class="kw">bf</span>(density_log <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>mass_log_stan <span class="op">+</span><span class="st"> </span>trophic_level),
      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> Intercept),
                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">5</span>), <span class="dt">class =</span> b),
                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">5</span>), <span class="dt">class =</span> b, <span class="dt">coef =</span> mass_log_stan),
                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">5</span>), <span class="dt">class =</span> sigma)),
      <span class="dt">iter =</span> <span class="dv">2000</span>,
      <span class="dt">warmup =</span> <span class="dv">1000</span>,
      <span class="dt">chains =</span> <span class="dv">4</span>,
      <span class="dt">cores =</span> <span class="dv">4</span>,
      <span class="dt">refresh =</span> <span class="dv">0</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(m_<span class="dv">2</span>)</code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: density_log ~ 1 + mass_log_stan + trophic_level 
##    Data: . (Number of observations: 746) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##                        Estimate Est.Error l-95% CI u-95% CI Eff.Sample
## Intercept                  3.15      0.10     2.95     3.35       3486
## mass_log_stan             -5.00      0.14    -5.28    -4.73       4164
## trophic_levelherbivore     1.29      0.15     0.99     1.59       3460
## trophic_levelcarnivore    -1.32      0.21    -1.73    -0.93       4052
##                        Rhat
## Intercept              1.00
## mass_log_stan          1.00
## trophic_levelherbivore 1.00
## trophic_levelcarnivore 1.00
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sigma     1.80      0.05     1.71     1.90       4443 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Now that we’ve fit our model with standardized data, we can directly compare the regression coefficients. With multiple predictors we might want to know which the relative importance of the predictors or which predictor has the largest effect size. In general, comparing effect sizes just means calculating the probability that the absolute value of the posterior distribution of one coefficient is greater than another. Remember that in math, magnitude means absolute value. So when you compare effect sizes, you are comparing the relative magnitudes of the regression coefficients.</p>
<p>For categorical predictors with more than 2 states, we might also want to know which categories are expected to have a greater expected value of <span class="math inline">\(y\)</span> than the other categories. The way parameters are estimated, our regression coefficients only describe the difference in expected <span class="math inline">\(y\)</span> between that state and the intercept/default state, but it does not describe the difference in expected <span class="math inline">\(y\)</span> between that state and any other non-default state. In our example, this means that the carnivora regression coefficient only describes the difference in expected population density between omnivores and carnivores, but not carnivores and herbivore.</p>
<p>Luckily, it is very easy to calculate the expected values of <span class="math inline">\(y\)</span> for each of categorical predictor’s states – then all state combinations can be compared directly. Here is a demonstration.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m_<span class="dv">2</span> <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">spread_draws</span>(b_Intercept, b_trophic_levelherbivore, b_trophic_levelcarnivore) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">transmute</span>(<span class="dt">omni =</span> b_Intercept,
         <span class="dt">herb =</span> b_Intercept <span class="op">+</span><span class="st"> </span>b_trophic_levelherbivore,
         <span class="dt">carn =</span> b_Intercept <span class="op">+</span><span class="st"> </span>b_trophic_levelcarnivore) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather</span>(<span class="dt">key =</span> trophic_state, <span class="dt">value =</span> value) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> value, 
                             <span class="dt">group =</span> trophic_state, 
                             <span class="dt">fill =</span> trophic_state)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_fill_viridis</span>(<span class="dt">discrete =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p><img src="paleo_book_files/figure-html/compare_states-1.png" width="672" /></p>
<p>The differences in expected <span class="math inline">\(y\)</span> between three states are extremely obvious, but you could imagine calculating the probability that one state is greater than another. Here is the trivial example.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m_<span class="dv">2</span> <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">spread_draws</span>(b_Intercept, b_trophic_levelherbivore, b_trophic_levelcarnivore) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">transmute</span>(<span class="dt">omni =</span> b_Intercept,
         <span class="dt">herb =</span> b_Intercept <span class="op">+</span><span class="st"> </span>b_trophic_levelherbivore,
         <span class="dt">carn =</span> b_Intercept <span class="op">+</span><span class="st"> </span>b_trophic_levelcarnivore) <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">summarize</span>(<span class="dt">omni_gr_herb =</span> <span class="kw">sum</span>(omni <span class="op">&gt;</span><span class="st"> </span>herb) <span class="op">/</span><span class="st"> </span><span class="kw">length</span>(omni),
                   <span class="dt">carn_gr_herb =</span> <span class="kw">sum</span>(carn <span class="op">&gt;</span><span class="st"> </span>herb) <span class="op">/</span><span class="st"> </span><span class="kw">length</span>(omni),
                   <span class="dt">carn_gr_omni =</span> <span class="kw">sum</span>(carn <span class="op">&gt;</span><span class="st"> </span>omni) <span class="op">/</span><span class="st"> </span><span class="kw">length</span>(omni)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather</span>(<span class="dt">key =</span> comparison, <span class="dt">value =</span> probability)</code></pre></div>
<pre><code>## # A tibble: 3 x 2
##   comparison   probability
##   &lt;chr&gt;              &lt;dbl&gt;
## 1 omni_gr_herb           0
## 2 carn_gr_herb           0
## 3 carn_gr_omni           0</code></pre>
</div>
<div id="checking-model-fit-1" class="section level2">
<h2><span class="header-section-number">5.7</span> Checking model fit</h2>
<p>So we’ve been able to fit our model and have (more) interpretable parameters. Our work with this model, however, is not done. As with our previous lessons, we now need to get an idea for how well our model represents our data – can we “trust” inferences based on its parameter estimates?</p>
<p>As I’ve stated before, there is no single best way of evaluating model fit. Let’s look at a lot of different aspects of model fit and make conclusions based on this host of evidence.</p>
<p>First, we check if the linear part of our model (i.e. the definition of <span class="math inline">\(\mu_{i}\)</span>) appears the capture mean population density. This means plotting the fitted draws against our data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pantheria_fit2 <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">add_fitted_draws</span>(<span class="dt">model =</span> m_<span class="dv">2</span>,
                   <span class="dt">n =</span> <span class="dv">100</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> mass_log_stan, <span class="dt">y =</span> density_log)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">y =</span> .value, <span class="dt">group =</span> .draw),
            <span class="dt">alpha =</span> <span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="dv">20</span>,
            <span class="dt">colour =</span> <span class="st">&#39;blue&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> pantheria_fit2, <span class="dt">size =</span> <span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_fill_brewer</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>trophic_level) <span class="op">+</span>
<span class="st">  </span><span class="ot">NULL</span></code></pre></div>
<p><img src="paleo_book_files/figure-html/multi_fitted-1.png" width="672" /></p>
<p>The linear predictor appears to cut through the “meat” of our data, though with so few carnivore observations it is hard to tell the quality of fit to those observations from this plot.</p>
<p>But the fitted draws are only the linear part of our model, and not our full posterior predictive distribution which includes our estimate of the scale of our data (i.e. <span class="math inline">\(\sigma\)</span>). Like before, we can generate the posterior predictive distribution of population density for the whole range of mass values and trophic levels. This is technically a type <em>counterfactual</em> plot because we are estimating values for unobserved values of body mass. However, we will overlay our data points over the posterior predictive distribution to visually compare how closely our estimates resemble the observed distribution of values.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pantheria_fit2 <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">data_grid</span>(<span class="dt">mass_log_stan =</span> <span class="kw">seq_range</span>(mass_log_stan, <span class="dt">n =</span> <span class="dv">1000</span>),
            trophic_level) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">add_predicted_draws</span>(<span class="dt">model =</span> m_<span class="dv">2</span>,
                      <span class="dt">n =</span> <span class="dv">100</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> mass_log_stan, <span class="dt">y =</span> density_log)) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_lineribbon</span>(<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">y =</span> .prediction),
                  <span class="dt">.width =</span> <span class="kw">c</span>(<span class="fl">0.9</span>, <span class="fl">0.5</span>, <span class="fl">0.1</span>),
                  <span class="dt">size =</span> <span class="dv">0</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> pantheria_fit2, <span class="dt">size =</span> <span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_fill_brewer</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>trophic_level) <span class="op">+</span>
<span class="st">  </span><span class="ot">NULL</span></code></pre></div>
<p><img src="paleo_book_files/figure-html/multi_predicted-1.png" width="672" /></p>
<p>Our data appears to sit over our posterior predictive distribution, with the concentration of points corresponding to the tighter credible intervals. However, this plot does not resolve our difficulty with evaluating our models fit to the carnivore observations.</p>
<p>We can also compare the density of our observations to those of draws from our posterior predictive distribution, something <a href="reg-continue.html#reg-continue">we have done before</a>. This involves simulating multiple (e.g. 100) datasets from the posterior predictive distribution and visually comparing these distributions to our observed. Because our previous plots weren’t able to help us resolve the quality of our model’s fit to our carnivore observations, let’s also break down our data by trophic level.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pantheria_fit2 <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">add_predicted_draws</span>(<span class="dt">model =</span> m_<span class="dv">2</span>,
                      <span class="dt">n =</span> <span class="dv">100</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> .prediction, <span class="dt">group =</span> .draw)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">stat =</span> <span class="st">&#39;density&#39;</span>,
            <span class="dt">alpha =</span> <span class="fl">0.1</span>,
            <span class="dt">colour =</span> <span class="st">&#39;blue&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">stat =</span> <span class="st">&#39;density&#39;</span>,
            <span class="dt">data =</span> pantheria_fit2,
            <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> density_log,
                          <span class="dt">group =</span> <span class="ot">NULL</span>),
            <span class="dt">colour =</span> <span class="st">&#39;black&#39;</span>,
            <span class="dt">size =</span> <span class="fl">1.5</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&#39;Population density &#39;</span>, <span class="kw">log</span>(n <span class="op">/</span><span class="st"> </span>km<span class="op">^</span><span class="dv">2</span>))),
       <span class="dt">title =</span> <span class="st">&#39;Population density, actual versus predicted&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>trophic_level) <span class="op">+</span>
<span class="st">  </span><span class="ot">NULL</span></code></pre></div>
<p><img src="paleo_book_files/figure-html/multi_dens_troph_ppc-1.png" width="672" /></p>
<p>Let’s also look our model’s ability to reconstruct specific point estimates. This means comparing point estimates from multiple (e.g. 100) posterior predictive datasets to those estimates from observed data. We’ve previously focused on the median population density for the trophic groups, but let’s also take a look at the standard deviation of population density for those groups – perhaps there is heterogeneity in the spread of population density between the groups that we’ve yet to consider.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pan_trophic_summary &lt;-
<span class="st">  </span>pantheria_fit2 <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(trophic_level) <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">summarize</span>(<span class="dt">median =</span> <span class="kw">median</span>(density_log),
                   <span class="dt">sd =</span> <span class="kw">sd</span>(density_log)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather</span>(key, value, median, sd)

pantheria_summary_ppc &lt;-<span class="st"> </span>
<span class="st">  </span>pantheria_fit2 <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">add_predicted_draws</span>(<span class="dt">model =</span> m_<span class="dv">2</span>,
                      <span class="dt">n =</span> <span class="dv">100</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(.draw, trophic_level) <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">summarize</span>(<span class="dt">median =</span> <span class="kw">median</span>(.prediction),
                   <span class="dt">sd =</span> <span class="kw">sd</span>(.prediction)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather</span>(key, value, median, sd)

pantheria_summary_ppc <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> value)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">fill =</span> <span class="st">&#39;blue&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">data =</span> pan_trophic_summary,
             <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">xintercept =</span> value),
             <span class="dt">size =</span> <span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_grid</span>(key <span class="op">~</span><span class="st"> </span>trophic_level, <span class="dt">scales =</span> <span class="st">&#39;free&#39;</span>, <span class="dt">switch =</span> <span class="st">&#39;y&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&#39;Median population density&#39;</span>, <span class="dt">y =</span> <span class="st">&#39;&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="ot">NULL</span></code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="paleo_book_files/figure-html/median_ppc-1.png" width="672" /></p>
<p>The current model is doing a much better job at capturing the median population densities compared to our <a href="reg-continue.html#reg-continue">previous model</a>. We also notice some evidence of heterogeneity in standard deviation between our groups – while our model does a good job at approximating the variation in population density of herbivores and omnivores, it fails to approximate that of carnivores. How do we resolve this situation? Do we need to deal with this in order to answer our scientific questions? Are we concerned with the spread of our data just as much as its central tendency?</p>
</div>
<div id="matrix-notation" class="section level2">
<h2><span class="header-section-number">5.8</span> Aside: Matrix Notation</h2>
<p>Regression models are frequently written in a compact form like <span class="math display">\[
\mu_{i} = \alpha + \sum^{n}_{j = 1} \beta_{j} x_{ji}
\]</span> where <span class="math inline">\(j\)</span> indexes each of the <span class="math inline">\(n\)</span> predictor variables. This statement can be unpacked as <span class="math display">\[
\mu_{i} = \alpha + \beta_{1} x_{1i} + \beta_{2} x_{2i} + \ldots + \beta_{n} x_{ni}.
\]</span></p>
<p>Both of these forms can be read as <span class="math inline">\(\mu\)</span> is modeled as the sum of an intercept and an additive combination of the products of parameters and predictors. This statement can be expressed more succinctly using matrix notation as <span class="math display">\[
\mu_{i} = X_{i} \beta,
\]</span> or even more succinctly as <span class="math display">\[
\mu = X \beta
\]</span> where <span class="math inline">\(\mu\)</span> is a vector of means, is a vector of regression coefficients, and X is a <em>design matrix</em>.</p>
<p>A design matrix has as mnay rows as the data, and as many columns as there are predictors plot one. This additional column is filled with 1s. These 1s are multiplied by the intercept and so return the unmodified intercept. Here is a quick visual on vector-matrix multiplication to help refresh your memory on how this all works to fit the vector <span class="math inline">\(\mu\)</span>: <img src="figures/wiki_matrix_multi.png" alt="https://commons.wikimedia.org/wiki/File:Matrix_multiplication_row_column_correspondance.svg" /></p>
<p>You might have realized that we’ve actually interacted with design matrices before when we were exploring how <a href="multiple-predictors-and-interactions-in-linear-regression.html#dummy">dummy coding is handled</a> – the column of all 1s called <code>Intercept</code> is eactly what I’ve described here. For example, we can peak at the design matrix from the regression model we developed in this lesson.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(pantheria_fit2 <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">model_matrix</span>(density_log <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>mass_log_stan <span class="op">+</span><span class="st"> </span>trophic_level))</code></pre></div>
<pre><code>## # A tibble: 746 x 4
##    `(Intercept)` mass_log_stan trophic_levelherbivore trophic_levelcarnivo…
##            &lt;dbl&gt;         &lt;dbl&gt;                  &lt;dbl&gt;                 &lt;dbl&gt;
##  1             1         0.967                      1                     0
##  2             1         0.333                      0                     0
##  3             1         0.321                      0                     0
##  4             1         0.357                      0                     1
##  5             1         0.517                      0                     1
##  6             1         1.05                       1                     0
##  7             1         1.01                       1                     0
##  8             1        -0.235                      0                     0
##  9             1        -0.282                      0                     0
## 10             1        -0.274                      0                     0
## # … with 736 more rows</code></pre>
<p>Each row of the design matrix is multiplied by a vector of regression coefficients (which includes the intercept term), which are summed to give the estimate of <span class="math inline">\(\mu\)</span>.</p>
</div>
<div id="summary-4" class="section level2">
<h2><span class="header-section-number">5.9</span> Summary</h2>
<p>This lesson covered linear models with more than one predictor variable. We continued our development of a regression model to explain variation in population density in mammals, using data from the PanTHERIA database. We returned to categorical variables and how they can be translated for use in regression models. Our newest model included body mass and trophic level as predictors of population density. We found that this model is an obvious improvement over the single predictor model from the previous less as more adequately describes the differences in population density assocaited with differences in body mass and torphic level. While our model is not a prefect descriptor of the data, it appears adequate for addressing questions relating to differences expected population density but not necessarily adequate for predicting the range of plausible population densities for carnivorous mammals.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="reg-continue.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="logistic-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": [["analytical_paleobiology.pdf", "PDF"], ["analytical_paleobiology.epub", "EPUB"]],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
