<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>3 Introduction to linear regression | Analytical Paleobiology</title>
  <meta name="description" content="An informal course on analytical paleobiology">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="3 Introduction to linear regression | Analytical Paleobiology" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="An informal course on analytical paleobiology" />
  <meta name="github-repo" content="psmits/paleo_book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Introduction to linear regression | Analytical Paleobiology" />
  <meta name="twitter:site" content="@PeterDSmits" />
  <meta name="twitter:description" content="An informal course on analytical paleobiology" />
  

<meta name="author" content="Peter D Smits">


<meta name="date" content="2019-03-22">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="introduction-to-bayesian-data-analysis.html">
<link rel="next" href="reg-continue.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="...">Short-Course on Analytical Paleobiology</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="managing-and-processing-data-from-the-paleobiology-database.html"><a href="managing-and-processing-data-from-the-paleobiology-database.html"><i class="fa fa-check"></i><b>1</b> Managing and Processing Data From the Paleobiology Database</a><ul>
<li class="chapter" data-level="1.1" data-path="managing-and-processing-data-from-the-paleobiology-database.html"><a href="managing-and-processing-data-from-the-paleobiology-database.html#objectives"><i class="fa fa-check"></i><b>1.1</b> Objectives</a></li>
<li class="chapter" data-level="1.2" data-path="managing-and-processing-data-from-the-paleobiology-database.html"><a href="managing-and-processing-data-from-the-paleobiology-database.html#project-reading"><i class="fa fa-check"></i><b>1.2</b> Reading</a></li>
<li class="chapter" data-level="1.3" data-path="managing-and-processing-data-from-the-paleobiology-database.html"><a href="managing-and-processing-data-from-the-paleobiology-database.html#introduction"><i class="fa fa-check"></i><b>1.3</b> Introduction</a></li>
<li class="chapter" data-level="1.4" data-path="managing-and-processing-data-from-the-paleobiology-database.html"><a href="managing-and-processing-data-from-the-paleobiology-database.html#getting-data"><i class="fa fa-check"></i><b>1.4</b> Getting data</a></li>
<li class="chapter" data-level="1.5" data-path="managing-and-processing-data-from-the-paleobiology-database.html"><a href="managing-and-processing-data-from-the-paleobiology-database.html#processing-data"><i class="fa fa-check"></i><b>1.5</b> Processing data</a></li>
<li class="chapter" data-level="1.6" data-path="managing-and-processing-data-from-the-paleobiology-database.html"><a href="managing-and-processing-data-from-the-paleobiology-database.html#binning-observations"><i class="fa fa-check"></i><b>1.6</b> Binning observations</a></li>
<li class="chapter" data-level="1.7" data-path="managing-and-processing-data-from-the-paleobiology-database.html"><a href="managing-and-processing-data-from-the-paleobiology-database.html#sharing-data"><i class="fa fa-check"></i><b>1.7</b> Sharing data</a></li>
<li class="chapter" data-level="1.8" data-path="managing-and-processing-data-from-the-paleobiology-database.html"><a href="managing-and-processing-data-from-the-paleobiology-database.html#summary"><i class="fa fa-check"></i><b>1.8</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html"><i class="fa fa-check"></i><b>2</b> Introduction to Bayesian data analysis</a><ul>
<li class="chapter" data-level="2.1" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#objectives-1"><i class="fa fa-check"></i><b>2.1</b> Objectives</a></li>
<li class="chapter" data-level="2.2" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#reading"><i class="fa fa-check"></i><b>2.2</b> Reading</a></li>
<li class="chapter" data-level="2.3" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#learning-from-data"><i class="fa fa-check"></i><b>2.3</b> Learning from data</a><ul>
<li class="chapter" data-level="2.3.1" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#counting-and-plausibility"><i class="fa fa-check"></i><b>2.3.1</b> Counting and plausibility</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#globe-example"><i class="fa fa-check"></i><b>2.4</b> Building a model</a><ul>
<li class="chapter" data-level="2.4.1" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#a-data-story"><i class="fa fa-check"></i><b>2.4.1</b> A data story</a></li>
<li class="chapter" data-level="2.4.2" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#bayesian-updating"><i class="fa fa-check"></i><b>2.4.2</b> Bayesian updating</a></li>
<li class="chapter" data-level="2.4.3" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#evaluate"><i class="fa fa-check"></i><b>2.4.3</b> Evaluate</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#terms-and-theory"><i class="fa fa-check"></i><b>2.5</b> Terms and theory</a></li>
<li class="chapter" data-level="2.6" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#bayes-theorem"><i class="fa fa-check"></i><b>2.6</b> Bayes’ Theorem</a></li>
<li class="chapter" data-level="2.7" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#but-how-does-it-work"><i class="fa fa-check"></i><b>2.7</b> But how does it <em>work</em>?</a><ul>
<li class="chapter" data-level="2.7.1" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#grid-approximation"><i class="fa fa-check"></i><b>2.7.1</b> Grid approximation</a></li>
<li class="chapter" data-level="2.7.2" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#markov-chain-monte-carlo"><i class="fa fa-check"></i><b>2.7.2</b> Markov chain Monte Carlo</a></li>
<li class="chapter" data-level="2.7.3" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#aside-on-interpreting-probabilities"><i class="fa fa-check"></i><b>2.7.3</b> Aside on Interpreting Probabilities</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#working-with-samples"><i class="fa fa-check"></i><b>2.8</b> Working with samples</a><ul>
<li class="chapter" data-level="2.8.1" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#intervals-of-defined-boundaries"><i class="fa fa-check"></i><b>2.8.1</b> Intervals of defined boundaries</a></li>
<li class="chapter" data-level="2.8.2" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#intervals-of-defined-mass"><i class="fa fa-check"></i><b>2.8.2</b> Intervals of defined mass</a></li>
<li class="chapter" data-level="2.8.3" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#point-estimates"><i class="fa fa-check"></i><b>2.8.3</b> Point estimates</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="introduction-to-bayesian-data-analysis.html"><a href="introduction-to-bayesian-data-analysis.html#summary-1"><i class="fa fa-check"></i><b>2.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="reg-intro.html"><a href="reg-intro.html"><i class="fa fa-check"></i><b>3</b> Introduction to linear regression</a><ul>
<li class="chapter" data-level="3.1" data-path="reg-intro.html"><a href="reg-intro.html#objectives-2"><i class="fa fa-check"></i><b>3.1</b> Objectives</a></li>
<li class="chapter" data-level="3.2" data-path="reg-intro.html"><a href="reg-intro.html#reading-1"><i class="fa fa-check"></i><b>3.2</b> Reading</a></li>
<li class="chapter" data-level="3.3" data-path="reg-intro.html"><a href="reg-intro.html#linear-regression"><i class="fa fa-check"></i><b>3.3</b> Linear regression</a><ul>
<li class="chapter" data-level="3.3.1" data-path="reg-intro.html"><a href="reg-intro.html#talking-about-models"><i class="fa fa-check"></i><b>3.3.1</b> Talking about models</a></li>
<li class="chapter" data-level="3.3.2" data-path="reg-intro.html"><a href="reg-intro.html#growing-a-regression-model"><i class="fa fa-check"></i><b>3.3.2</b> Growing a regression model</a></li>
<li class="chapter" data-level="3.3.3" data-path="reg-intro.html"><a href="reg-intro.html#sampling-from-the-model"><i class="fa fa-check"></i><b>3.3.3</b> Sampling from the model</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="reg-intro.html"><a href="reg-intro.html#adding-a-predictor-to-the-mix"><i class="fa fa-check"></i><b>3.4</b> Adding a predictor to the mix</a><ul>
<li class="chapter" data-level="3.4.1" data-path="reg-intro.html"><a href="reg-intro.html#aside-dummy-coding"><i class="fa fa-check"></i><b>3.4.1</b> Aside: Dummy coding</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="reg-intro.html"><a href="reg-intro.html#interpreting-the-model-fit"><i class="fa fa-check"></i><b>3.5</b> Interpreting the model fit</a><ul>
<li class="chapter" data-level="3.5.1" data-path="reg-intro.html"><a href="reg-intro.html#linear-predictor"><i class="fa fa-check"></i><b>3.5.1</b> Linear predictor</a></li>
<li class="chapter" data-level="3.5.2" data-path="reg-intro.html"><a href="reg-intro.html#posterior-prediction"><i class="fa fa-check"></i><b>3.5.2</b> Posterior prediction</a></li>
<li class="chapter" data-level="3.5.3" data-path="reg-intro.html"><a href="reg-intro.html#posterior-predictive-tests"><i class="fa fa-check"></i><b>3.5.3</b> Posterior predictive tests</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="reg-intro.html"><a href="reg-intro.html#summary-2"><i class="fa fa-check"></i><b>3.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="reg-continue.html"><a href="reg-continue.html"><i class="fa fa-check"></i><b>4</b> Continuing with regression with continuous predictors</a><ul>
<li class="chapter" data-level="4.1" data-path="reg-continue.html"><a href="reg-continue.html#objectives-3"><i class="fa fa-check"></i><b>4.1</b> Objectives</a></li>
<li class="chapter" data-level="4.2" data-path="reg-continue.html"><a href="reg-continue.html#reading-2"><i class="fa fa-check"></i><b>4.2</b> Reading</a></li>
<li class="chapter" data-level="4.3" data-path="reg-continue.html"><a href="reg-continue.html#our-first-example"><i class="fa fa-check"></i><b>4.3</b> Our first example</a></li>
<li class="chapter" data-level="4.4" data-path="reg-continue.html"><a href="reg-continue.html#a-single-continuous-predictor"><i class="fa fa-check"></i><b>4.4</b> A single continuous predictor</a><ul>
<li class="chapter" data-level="4.4.1" data-path="reg-continue.html"><a href="reg-continue.html#aside-centering"><i class="fa fa-check"></i><b>4.4.1</b> Aside: Centering</a></li>
<li class="chapter" data-level="4.4.2" data-path="reg-continue.html"><a href="reg-continue.html#checking-model-fit"><i class="fa fa-check"></i><b>4.4.2</b> Checking model fit</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="reg-continue.html"><a href="reg-continue.html#summary-3"><i class="fa fa-check"></i><b>4.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="multiple-predictors-and-interactions-in-linear-regression.html"><a href="multiple-predictors-and-interactions-in-linear-regression.html"><i class="fa fa-check"></i><b>5</b> Multiple predictors and interactions in linear regression</a><ul>
<li class="chapter" data-level="5.1" data-path="multiple-predictors-and-interactions-in-linear-regression.html"><a href="multiple-predictors-and-interactions-in-linear-regression.html#objectives-4"><i class="fa fa-check"></i><b>5.1</b> Objectives</a></li>
<li class="chapter" data-level="5.2" data-path="multiple-predictors-and-interactions-in-linear-regression.html"><a href="multiple-predictors-and-interactions-in-linear-regression.html#reading-3"><i class="fa fa-check"></i><b>5.2</b> Reading</a></li>
<li class="chapter" data-level="5.3" data-path="multiple-predictors-and-interactions-in-linear-regression.html"><a href="multiple-predictors-and-interactions-in-linear-regression.html#more-than-one-predictor"><i class="fa fa-check"></i><b>5.3</b> More than one predictor</a><ul>
<li class="chapter" data-level="5.3.1" data-path="multiple-predictors-and-interactions-in-linear-regression.html"><a href="multiple-predictors-and-interactions-in-linear-regression.html#dummy"><i class="fa fa-check"></i><b>5.3.1</b> Categorical predictor</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="multiple-predictors-and-interactions-in-linear-regression.html"><a href="multiple-predictors-and-interactions-in-linear-regression.html#defining-our-model"><i class="fa fa-check"></i><b>5.4</b> Defining our model</a></li>
<li class="chapter" data-level="5.5" data-path="multiple-predictors-and-interactions-in-linear-regression.html"><a href="multiple-predictors-and-interactions-in-linear-regression.html#fitting-model-in-brms"><i class="fa fa-check"></i><b>5.5</b> Fitting model in <code>brms</code></a></li>
<li class="chapter" data-level="5.6" data-path="multiple-predictors-and-interactions-in-linear-regression.html"><a href="multiple-predictors-and-interactions-in-linear-regression.html#aside-standardizing"><i class="fa fa-check"></i><b>5.6</b> Aside: Standardizing</a></li>
<li class="chapter" data-level="5.7" data-path="multiple-predictors-and-interactions-in-linear-regression.html"><a href="multiple-predictors-and-interactions-in-linear-regression.html#checking-model-fit-1"><i class="fa fa-check"></i><b>5.7</b> Checking model fit</a></li>
<li class="chapter" data-level="5.8" data-path="multiple-predictors-and-interactions-in-linear-regression.html"><a href="multiple-predictors-and-interactions-in-linear-regression.html#matrix-notation"><i class="fa fa-check"></i><b>5.8</b> Aside: Matrix Notation</a></li>
<li class="chapter" data-level="5.9" data-path="multiple-predictors-and-interactions-in-linear-regression.html"><a href="multiple-predictors-and-interactions-in-linear-regression.html#summary-4"><i class="fa fa-check"></i><b>5.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>6</b> Logistic regression</a><ul>
<li class="chapter" data-level="6.1" data-path="logistic-regression.html"><a href="logistic-regression.html#objectives-5"><i class="fa fa-check"></i><b>6.1</b> Objectives</a></li>
<li class="chapter" data-level="6.2" data-path="logistic-regression.html"><a href="logistic-regression.html#reading-4"><i class="fa fa-check"></i><b>6.2</b> Reading</a></li>
<li class="chapter" data-level="6.3" data-path="logistic-regression.html"><a href="logistic-regression.html#introduction-1"><i class="fa fa-check"></i><b>6.3</b> Introduction</a></li>
<li class="chapter" data-level="6.4" data-path="logistic-regression.html"><a href="logistic-regression.html#foram-coiling"><i class="fa fa-check"></i><b>6.4</b> Foram coiling</a></li>
<li class="chapter" data-level="6.5" data-path="logistic-regression.html"><a href="logistic-regression.html#writing-out-a-model"><i class="fa fa-check"></i><b>6.5</b> Writing out a model</a><ul>
<li class="chapter" data-level="6.5.1" data-path="logistic-regression.html"><a href="logistic-regression.html#interpreting-logistic-regression-coefficients"><i class="fa fa-check"></i><b>6.5.1</b> Interpreting logistic regression coefficients</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="logistic-regression.html"><a href="logistic-regression.html#priors-for-our-model"><i class="fa fa-check"></i><b>6.6</b> Priors for our model</a></li>
<li class="chapter" data-level="6.7" data-path="logistic-regression.html"><a href="logistic-regression.html#fitting-our-model"><i class="fa fa-check"></i><b>6.7</b> Fitting our model</a></li>
<li class="chapter" data-level="6.8" data-path="logistic-regression.html"><a href="logistic-regression.html#checking-model-adequacy"><i class="fa fa-check"></i><b>6.8</b> Checking model adequacy</a></li>
<li class="chapter" data-level="6.9" data-path="logistic-regression.html"><a href="logistic-regression.html#summary-5"><i class="fa fa-check"></i><b>6.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="poisson-regression-and-others-glms.html"><a href="poisson-regression-and-others-glms.html"><i class="fa fa-check"></i><b>7</b> Poisson regression and others GLMs</a><ul>
<li class="chapter" data-level="7.1" data-path="poisson-regression-and-others-glms.html"><a href="poisson-regression-and-others-glms.html#outline"><i class="fa fa-check"></i><b>7.1</b> Outline</a></li>
<li class="chapter" data-level="7.2" data-path="poisson-regression-and-others-glms.html"><a href="poisson-regression-and-others-glms.html#poisson-distribution"><i class="fa fa-check"></i><b>7.2</b> Poisson distribution</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="varying-intercepts.html"><a href="varying-intercepts.html"><i class="fa fa-check"></i><b>8</b> Varying-intercept(s)</a><ul>
<li class="chapter" data-level="8.1" data-path="varying-intercepts.html"><a href="varying-intercepts.html#objectives-6"><i class="fa fa-check"></i><b>8.1</b> Objectives</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="varying-slopes.html"><a href="varying-slopes.html"><i class="fa fa-check"></i><b>9</b> Varying slope(s)</a></li>
<li class="chapter" data-level="10" data-path="varying-slopes-and-intercepts.html"><a href="varying-slopes-and-intercepts.html"><i class="fa fa-check"></i><b>10</b> Varying slopes and intercepts</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown">
Proudly published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Analytical Paleobiology</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="reg-intro" class="section level1">
<h1><span class="header-section-number">3</span> Introduction to linear regression</h1>
<div id="objectives-2" class="section level2">
<h2><span class="header-section-number">3.1</span> Objectives</h2>
<ul>
<li>Set up a linear regression model.</li>
<li>Interpret the parameters of a regression model.</li>
<li>Communicate a model descriptions to others.</li>
<li>Fit regression models in <strong>brms</strong>.</li>
<li>Basics of summarizing and visualizing a model fit.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(pacman)

<span class="kw">p_load</span>(tidyverse, modelr, brms, tidybayes, here)

<span class="kw">theme_set</span>(<span class="kw">theme_bw</span>())</code></pre></div>
</div>
<div id="reading-1" class="section level2">
<h2><span class="header-section-number">3.2</span> Reading</h2>
<p>The following materials are recommended pre-readings before starting this tutorial.</p>
<ul>
<li>Chapter 4 “Linear Models” from <a href="https://xcelab.net/rm/statistical-rethinking/"><strong>Statistical Rethinking</strong> by Richard McElreath</a>.</li>
<li>OPTIONAL Chapter 3 “Sampling the Imaginary” from <a href="https://xcelab.net/rm/statistical-rethinking/"><strong>Statistical Rethinking</strong> by Richard McElreath</a>.</li>
<li>OPTIONAL Chapter 3 “Linear regression: the basics” from <a href="https://www.cambridge.org/core/books/data-analysis-using-regression-and-multilevelhierarchical-models/32A29531C7FD730C3A68951A17C9D983"><strong>Data Analysis Using Regression and Multilevel/Hierarchical Models</strong> by Gelman and Hill</a>.</li>
</ul>
</div>
<div id="linear-regression" class="section level2">
<h2><span class="header-section-number">3.3</span> Linear regression</h2>
<p>Linear regression refers to a large family of statistical models which attempt to learn about the mean and variance of some measurement, using an additive combination of other measures. Linear regression is a descriptive model that corresponds to many different processes.</p>
<p>Normally regression is presented as a way of representing the relationship between two or more variables. I believe this description obscures the interpretation and meaning of regression results. Instead, we’re going to think of linear regression as a method that summarizes how the <em>average</em> or expected values of a numerical outcome vary as a linear functions of one or more predictors.</p>
<p>Regression can be used to predict an outcome given a linear function of those predictors, and regression coefficients can be thought of as comparisons across predicted values or as comparisons among averages in the data. A regression coefficient describes the expected change in the response per unit change in its predictor. Linear regression uses a Gaussian/Normal distribution to describe the distribution of our measurement of interest. Like any model, linear regression is not universally applicable. But linear regression is pretty foundational in statistics because once you can build and interpret a linear regression model, it is easy to move on to other types of regression for when things aren’t Normal.</p>
<p>Models of normally distributed data are very common: t-test, single regression, multiple regression, ANOVA, ANCOVA, MANOVA, MANCOVA, etc. All of these models are functionally equivalent. Learning and understanding each of these special cases is a lot of unnecessary work; instead, we’re going to focus on a general modeling strategy that subsumes all of these special cases as just variations on a theme. Additionally, we’re going to cover a statistical notation for communicating a model that encodes all of our assumptions and presents them clearly for other readers (including yourself in the future).</p>
<div id="talking-about-models" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Talking about models</h3>
<p>Here are the choices encoded in a model description:</p>
<ol style="list-style-type: decimal">
<li>Outcome variable or variables that we hope to predict or understand (<span class="math inline">\(y\)</span>).</li>
<li>Likelihood distribution that defines the plausibility of the individual observations.</li>
<li>Predictors or covariates – a set of other measurements that we hope to use to predict or understand the outcome (<span class="math inline">\(X\)</span>).</li>
<li>Relation between the shape of the likelihood distribution (e.g. location and scale) to the predictor variables. The nature of this relation forces us to define all the parameters of the model.</li>
<li>Priors for all of the parameters in the model.</li>
</ol>
<p>Here’s the globe tossing model from last week <span class="math display">\[
\begin{align} 
w &amp;\sim \text{Binomial}(n, p) \\
p &amp;\sim \text{Uniform}(0, 1). \\
\end{align}
\]</span> The <span class="math inline">\(\sim\)</span> symbol indicates a stochastic relationship. A stochastic relationship means that the variable or parameter is mapped onto a distribution of values. It is stochastic because no single instance of the variable on the left is known with certainty. This relationship is probabilistic as some values are more plausible than others, though there are many plausible values under any model.</p>
<p>Can you identify the various parts of this model description?</p>
<p>This notation allows us to specify and communicate our model clearly so that other people can understand what we’re doing. This language is general, and can be used to describe all model types. It is ok if you do not immediately understand this notation; that’s a normal part of learning. By continuing to use this notation, we will build familiarity with this syntax.</p>
</div>
<div id="growing-a-regression-model" class="section level3">
<h3><span class="header-section-number">3.3.2</span> Growing a regression model</h3>
<p>We’re going to use a real dataset of invertebrate valve sizes and slowly build up a regression model to describe differences between taxonomic groups. We will begin with a proto-regression model and then add predictors.</p>
<p>The dataset we’re going to have fun with as part of today’s activities is the Bivalve and Brachiopod body size data from <a href="http://rspb.royalsocietypublishing.org/content/281/1783/20133122.long">Payne et al. 2014 ProcB</a>. Their data includes location, age, type, and valve length. Load the “occurrence” tab-delimited file and start exploring the distribution of body sizes.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># `here` allows us to grab from subdirectory without formally specifying path </span>
<span class="co"># allows portability</span>
r &lt;-<span class="st"> </span><span class="kw">read_tsv</span>(<span class="kw">here</span>(<span class="st">&#39;data&#39;</span>, <span class="st">&#39;payne_bodysize&#39;</span>, <span class="st">&#39;Occurrence_PaleoDB.txt&#39;</span>)) </code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   taxon_name = col_character(),
##   pbdb_collection_no = col_double(),
##   p_lat = col_double(),
##   p_lng = col_double(),
##   int_midpoint = col_double(),
##   taxon = col_character(),
##   sub = col_character(),
##   size = col_double()
## )</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># modify raw data for use</span>
<span class="co"># genus can occur 1+ times</span>
(d &lt;-<span class="st"> </span>r <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(taxon_name, taxon) <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">summarize</span>(<span class="dt">size =</span> <span class="kw">mean</span>(size)) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># is this always a good idea?</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">size_log =</span> <span class="kw">log</span>(size)) <span class="op">%&gt;%</span><span class="st">    </span><span class="co"># log transform</span>
<span class="st">    </span><span class="kw">ungroup</span>())</code></pre></div>
<pre><code>## # A tibble: 3,980 x 4
##    taxon_name    taxon   size size_log
##    &lt;chr&gt;         &lt;chr&gt;  &lt;dbl&gt;    &lt;dbl&gt;
##  1 Abra          Biv    38       3.64 
##  2 Abrekia       Bra    11.6     2.45 
##  3 Abruptolopha  Biv    98.8     4.59 
##  4 Acambona      Bra    39.9     3.69 
##  5 Acanthalosia  Bra    37.5     3.62 
##  6 Acanthambonia Bra     1.74    0.556
##  7 Acanthatia    Bra    23.5     3.16 
##  8 Acanthocardia Biv   102.      4.63 
##  9 Acanthocosta  Bra    24.5     3.20 
## 10 Acanthopecten Biv    12.1     2.50 
## # … with 3,970 more rows</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># look at the data</span>
d <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">gather</span>(key, value, size, size_log) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> value)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">stat_bin</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>key, <span class="dt">scales =</span> <span class="st">&#39;free_x&#39;</span>, <span class="dt">switch =</span> <span class="st">&#39;x&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&#39;valve length&#39;</span>)</code></pre></div>
<pre><code>## Warning: &#39;switch&#39; is deprecated.
## Use &#39;strip.position&#39; instead.
## See help(&quot;Deprecated&quot;)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="paleo_book_files/figure-html/load_payne_data-1.png" width="672" /></p>
<p>Linear regression uses a Gaussian distribution to describe a continuous variable of interest. The Gaussian distribution at the center of linear regression has two parameters describing the shape of the distribution – mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>. Here’s a quick picture of a Gaussian distribution, play around with the mean and standard deviation parameters.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> <span class="kw">tibble</span>(<span class="dt">x =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">-25</span>, <span class="dt">to =</span> <span class="dv">25</span>, <span class="dt">by =</span> <span class="fl">0.1</span>)),
       <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> <span class="kw">dnorm</span>(x, <span class="dt">mean =</span> <span class="dv">5</span>, <span class="dt">sd =</span> <span class="dv">1000</span>))) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>)</code></pre></div>
<p><img src="paleo_book_files/figure-html/example_distribution-1.png" width="672" /></p>
<p>The way Bayesian updating works means we want to consider all possible combinations of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> and rank them by posterior plausibility. The posterior is in effect a distribution of plausible Gaussian distributions.</p>
<p>To define the log valve length as Gaussian distributed with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>, we write <span class="math display">\[
s_{i} \sim \text{Normal}(\mu, \sigma).
\]</span></p>
<p>What do the different terms and symbols in this statement mean?</p>
<p>To complete this model we need to define the priors for the parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>. We need a joint prior <span class="math inline">\(Pr(\mu, \sigma)\)</span>, but most of the time we can just define independent priors for each parameter – this is equivalent to saying <span class="math inline">\(Pr(\mu, \sigma) = Pr(\mu)Pr(\sigma)\)</span>. Here’s a more complete look at the Gaussian model of log valve length: <span class="math display">\[
\begin{align}
s_{i} &amp;\sim \text{Normal}(\mu, \sigma) \\
\mu &amp;\sim \text{Normal}(3, 10) \\
\sigma &amp;\sim \text{Uniform}(0, 20) \\
\end{align}
\]</span> What do each of these three lines mean?</p>
<p>Let’s discuss the choice of priors for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>. It is a good idea to plot your priors so that you can better understand your assumptions.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># prior for mean of log valve length</span>
<span class="kw">ggplot</span>(<span class="dt">data =</span> <span class="kw">tibble</span>(<span class="dt">x =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">-50</span>, <span class="dt">to =</span> <span class="dv">50</span>, <span class="dt">by =</span> <span class="fl">.1</span>)),
       <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> <span class="kw">dnorm</span>(x, <span class="dt">mean =</span> <span class="dv">3</span>, <span class="dt">sd =</span> <span class="dv">10</span>))) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="kw">expression</span>(mu))</code></pre></div>
<p><img src="paleo_book_files/figure-html/vis_priors-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># prior for standard deviation of log valve length</span>
<span class="kw">ggplot</span>(<span class="dt">data =</span> <span class="kw">tibble</span>(<span class="dt">x =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="dv">30</span>, <span class="dt">by =</span> <span class="fl">.1</span>)),
       <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> <span class="kw">dunif</span>(x, <span class="dt">min =</span> <span class="dv">0</span>, <span class="dt">max =</span> <span class="dv">20</span>))) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="kw">expression</span>(sigma))</code></pre></div>
<p><img src="paleo_book_files/figure-html/vis_priors-2.png" width="672" /></p>
<p>But what do these distributions <em>mean</em> for the distribution of log valve lengths? These individual priors imply the full distribution of lengths, so let’s simulate them together and plot those results:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="fl">1e4</span>                               <span class="co"># number of samples</span>

<span class="kw">tibble</span>(<span class="dt">sample_mu =</span> <span class="kw">rnorm</span>(n, <span class="dt">mean =</span> <span class="dv">5</span>, <span class="dt">sd =</span> <span class="dv">5</span>),
       <span class="dt">sample_sigma =</span> <span class="kw">runif</span>(n, <span class="dt">min =</span> <span class="dv">0</span>, <span class="dt">max =</span> <span class="dv">10</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">x =</span> <span class="kw">rnorm</span>(n, <span class="dt">mean =</span> sample_mu, <span class="dt">sd =</span> sample_sigma)) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># joint distribution</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x)) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_density</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&quot;Prior predictive distribution for &quot;</span>, <span class="kw">italic</span>(s[i]))))</code></pre></div>
<p><img src="paleo_book_files/figure-html/prior_predictive-1.png" width="672" /></p>
<p>The resulting distribution describes the relative prior plausibilities we’ve defined for log valve lengths. Play around with the numbers in the priors and see its effect on the prior probability density of log valve lengths.</p>
</div>
<div id="sampling-from-the-model" class="section level3">
<h3><span class="header-section-number">3.3.3</span> Sampling from the model</h3>
<p>Now that we’ve completely defined out model (likelihood, data to condition on, parameters, and priors for all parameters) we can estimate the posterior plausibilities of our parameter values.</p>
<p>We’re going to use the <code>brms</code> package to fit our model. This package was briefly introduced at the end of last lesson, and we’re going to get more experience with it today. After we fit the model, we’ll use functions from <code>tidybayes</code> that will help us extract and visualize our posterior distribution.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">brm</span>(<span class="dt">data =</span> d, 
           <span class="dt">family =</span> <span class="kw">gaussian</span>(), 
           <span class="dt">formula =</span> <span class="kw">bf</span>(size_log <span class="op">~</span><span class="st"> </span><span class="dv">1</span>), 
           <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">3</span>, <span class="dv">10</span>), <span class="dt">class =</span> Intercept), 
                     <span class="kw">prior</span>(<span class="kw">uniform</span>(<span class="dv">0</span>, <span class="dv">20</span>), <span class="dt">class =</span> sigma)),
           <span class="dt">iter =</span> <span class="dv">2000</span>,                 <span class="co"># default</span>
           <span class="dt">warmup =</span> <span class="dv">1000</span>,               <span class="co"># 1/2 iter</span>
           <span class="dt">chains =</span> <span class="dv">4</span>,                  <span class="co"># each chain is a set of samples</span>
           <span class="dt">cores =</span> <span class="dv">4</span>,                   <span class="co"># parallel processing; this might not work on your computer</span>
           <span class="dt">refresh =</span> <span class="dv">0</span>)                 <span class="co"># less text output</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># what does the brm object look like?</span>
<span class="kw">print</span>(m_<span class="dv">1</span>)</code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: size_log ~ 1 
##    Data: d (Number of observations: 3980) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept     3.20      0.01     3.17     3.23       2991 1.00
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sigma     0.92      0.01     0.90     0.94       3196 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># what do the estimates and chains look like?</span>
<span class="kw">plot</span>(m_<span class="dv">1</span>)</code></pre></div>
<p><img src="paleo_book_files/figure-html/inspect_model_fit-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># what are the parameter named?</span>
<span class="kw">get_variables</span>(m_<span class="dv">1</span>)</code></pre></div>
<pre><code>## [1] &quot;b_Intercept&quot;   &quot;sigma&quot;         &quot;lp__&quot;          &quot;accept_stat__&quot;
## [5] &quot;stepsize__&quot;    &quot;treedepth__&quot;   &quot;n_leapfrog__&quot;  &quot;divergent__&quot;  
## [9] &quot;energy__&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># extract the samples</span>
m_<span class="dv">1</span> <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">spread_draws</span>(b_Intercept, sigma)</code></pre></div>
<pre><code>## # A tibble: 4,000 x 5
##    .chain .iteration .draw b_Intercept sigma
##     &lt;int&gt;      &lt;int&gt; &lt;int&gt;       &lt;dbl&gt; &lt;dbl&gt;
##  1      1          1     1        3.20 0.919
##  2      1          2     2        3.20 0.913
##  3      1          3     3        3.19 0.919
##  4      1          4     4        3.19 0.931
##  5      1          5     5        3.21 0.903
##  6      1          6     6        3.21 0.907
##  7      1          7     7        3.21 0.916
##  8      1          8     8        3.20 0.932
##  9      1          9     9        3.21 0.910
## 10      1         10    10        3.21 0.909
## # … with 3,990 more rows</code></pre>
<p>We now have 4000 samples from the joint posterior. How do we want to summarize them? Here are some examples:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># median and 95% quantile interval</span>
m_<span class="dv">1</span> <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather_draws</span>(b_Intercept, sigma) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">median_qi</span>()                          <span class="co"># ?brms::point_interval for documentation</span></code></pre></div>
<pre><code>## # A tibble: 2 x 7
##   .variable   .value .lower .upper .width .point .interval
##   &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    
## 1 b_Intercept  3.20   3.17   3.23    0.95 median qi       
## 2 sigma        0.916  0.896  0.936   0.95 median qi</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># posterior predictive distribution</span>
m_<span class="dv">1</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">add_predicted_draws</span>(<span class="dt">newdata =</span> d,     <span class="co"># original data gives to simulate from</span>
                      <span class="dt">model =</span> .,       <span class="co"># the model we want the PPD from</span>
                      <span class="dt">n =</span> <span class="dv">100</span>) <span class="op">%&gt;%</span><span class="st">     </span><span class="co"># how many draws from PPD per observation</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> .prediction, <span class="dt">group =</span> .draw)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">stat =</span> <span class="st">&#39;density&#39;</span>, 
            <span class="dt">alpha =</span> <span class="fl">0.1</span>, 
            <span class="dt">colour =</span> <span class="st">&#39;blue&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">stat =</span> <span class="st">&#39;density&#39;</span>, 
            <span class="dt">data =</span> d,                  <span class="co"># compare to original data distribution</span>
            <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> size_log, 
                          <span class="dt">group =</span> <span class="ot">NULL</span>), 
            <span class="dt">colour =</span> <span class="st">&#39;black&#39;</span>,
            <span class="dt">size =</span> <span class="fl">1.5</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&#39;log valve length&#39;</span>)</code></pre></div>
<p><img src="paleo_book_files/figure-html/summary_point_pi-1.png" width="672" /></p>
<p>We will be discussing the posterior predictive distribution further later in the lesson. For now, think of this as the distribution of outcomes implied by our model – the distribution of plausible distributions.</p>
</div>
</div>
<div id="adding-a-predictor-to-the-mix" class="section level2">
<h2><span class="header-section-number">3.4</span> Adding a predictor to the mix</h2>
<p>Currently, our model doesn’t really resemble what we think of as “regression.” Typically, we want to understand how the mean of our outcome variable is related to one or more predictor variables.</p>
<p>Let’s start with a basic analysis questions: do Bivalves and Brachiopods differ in valve length and how? Start by looking at the data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">d <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">taxon =</span> <span class="kw">recode</span>(taxon,
                        <span class="dt">Biv =</span> <span class="st">&#39;Bivalvia&#39;</span>,
                        <span class="dt">Bra =</span> <span class="st">&#39;Brachiopoda&#39;</span>)) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># make text clearer </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> taxon, <span class="dt">y =</span> size_log)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_violin</span>(<span class="dt">fill =</span> <span class="st">&#39;grey60&#39;</span>, <span class="dt">colour =</span> <span class="ot">NA</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_jitter</span>(<span class="dt">height =</span> <span class="dv">0</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&#39;taxon&#39;</span>, <span class="dt">y =</span> <span class="st">&#39;log valve length&#39;</span>)</code></pre></div>
<p><img src="paleo_book_files/figure-html/vis_comparison-1.png" width="672" /></p>
<p>To build a linear model the strategy is to make the parameter for the mean of the Gaussian distribution, <span class="math inline">\(\mu\)</span>, into a linear function of the predictor variable and other, new parameters we invent. A linear model means that we assume that the predictors have a perfectly constant and additive relationship to the mean of the outcome.</p>
<p>Currently, our model looks like this: <span class="math display">\[
\begin{align}
s_{i} &amp;\sim \text{Normal}(\mu, \sigma) \\
\mu &amp;\sim \text{Normal}(3, 10) \\
\sigma &amp;\sim \text{Uniform}(0, 20) \\
\end{align}
\]</span></p>
<p>How do we add “Bivalve vs Brachiopod” to our model of valve size?</p>
<p>First, let the mathematical name of the column “taxon” from the tibble <code>d</code> be called <span class="math inline">\(x\)</span>. This variable <span class="math inline">\(x\)</span> is a predictor variable that can take one of two values: 0 for Biv(alve), and 1 for Bra(chiopod). Additionally, this vector has the same length as <span class="math inline">\(s\)</span>. How do we then express how <span class="math inline">\(x\)</span> describes or predicts the values of <span class="math inline">\(s\)</span>?</p>
<p>To get taxonomic group into the model, we need to define <span class="math inline">\(\mu\)</span> as a function of the values in <span class="math inline">\(x\)</span>. Here’s how we could do this: <span class="math display">\[
\begin{align}
s_{i} &amp;\sim \text{Normal}(\mu_{i}, \sigma) \\
\mu_{i} &amp;= \alpha + \beta x_{i}\\
\alpha &amp;\sim \text{Normal}(3, 10) \\
\beta &amp;\sim \text{Normal}(0, 10) \\
\sigma &amp;\sim \text{Uniform}(0, 20) \\
\end{align}
\]</span> What do each of the lines in the model represent? What has changed and why?</p>
<p>But where did <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> come from? We made them up! <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> are necessary and sufficient for describing the Gaussian distribution. <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are devices we invent for manipulating <span class="math inline">\(\mu\)</span>, allowing it vary across cases in our data.</p>
<p>Making up new parameters like <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> is a common strategy for expanding the amount of information in our model. These parameters are targets of our learning – each must be described in the posterior density. When we want to learn something, we invent a parameter (or parameters) describing it.</p>
<p>In the case of the linear model, <span class="math inline">\(\mu_{i} = \alpha + \beta x_{i}\)</span>, we are now asking two questions about the mean of <span class="math inline">\(s\)</span> instead of just one.</p>
<ol style="list-style-type: decimal">
<li>What is the expected log valve length when <span class="math inline">\(x_{i} = 0\)</span> (e.g. species is a Bivalve)? The parameter <span class="math inline">\(\alpha\)</span> answers this question. For this reason, <span class="math inline">\(\alpha\)</span> is called the <em>intercept</em>.</li>
<li>What is the change in expected log valve length, when <span class="math inline">\(x_{i}\)</span> changes by 1 unit? The parameter <span class="math inline">\(\beta\)</span> answers this questions, and is often called a slope.</li>
</ol>
<p>These two parameters along with <span class="math inline">\(x\)</span> describe a line that passes through <span class="math inline">\(\alpha\)</span> when <span class="math inline">\(x_{i} = 0\)</span> and has slope <span class="math inline">\(\beta\)</span>.</p>
<p>Remember that <span class="math inline">\(x\)</span> is a binary vector – it only takes on one of two values: 0 or 1. For a binary predictor, the regression coefficient is interpreted as the difference between the averages of the two groups.</p>
<p>Let’s think more about this choice of prior. Do you think there is an equal chance that average brachiopod valves are larger or smaller than bivalves? In this context, we have so much data that this is harmless. In other contexts, our sampler might need more information to finds its target.</p>
<p>So let’s fit the model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">brm</span>(<span class="dt">data =</span> d, 
           <span class="dt">family =</span> <span class="kw">gaussian</span>(),
           <span class="dt">formula =</span> size_log <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>taxon,
           <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">3</span>, <span class="dv">10</span>), <span class="dt">class =</span> Intercept),
                     <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> b),
                     <span class="kw">prior</span>(<span class="kw">uniform</span>(<span class="dv">0</span>, <span class="dv">20</span>), <span class="dt">class =</span> sigma)), 
           <span class="dt">iter =</span> <span class="dv">2000</span>,                <span class="co"># default</span>
           <span class="dt">warmup =</span> <span class="dv">1000</span>,              <span class="co"># 1/2 iter</span>
           <span class="dt">chains =</span> <span class="dv">4</span>,                 <span class="co"># each chain is a set of samples</span>
           <span class="dt">cores =</span> <span class="dv">4</span>,                  <span class="co"># parallel processing; this might not work on your computer!</span>
           <span class="dt">refresh =</span> <span class="dv">0</span>)                <span class="co"># less text output</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># look at the brm summary</span>
<span class="kw">print</span>(m_<span class="dv">2</span>)</code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: size_log ~ 1 + taxon 
##    Data: d (Number of observations: 3980) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept     3.69      0.02     3.65     3.74       3739 1.00
## taxonBra     -0.77      0.03    -0.82    -0.71       3535 1.00
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sigma     0.84      0.01     0.82     0.86       3978 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># look at the brm plot</span>
<span class="kw">plot</span>(m_<span class="dv">2</span>)</code></pre></div>
<p><img src="paleo_book_files/figure-html/inspect_binary_model-1.png" width="672" /></p>
<div id="aside-dummy-coding" class="section level3">
<h3><span class="header-section-number">3.4.1</span> Aside: Dummy coding</h3>
<p><code>brm</code>, and R in general, will automatically translate categorical predictors like our taxon variable into what’s called <em>dummy coding</em>. Here’s an illustration of what that means using the subtype variable “sub” from our raw data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">r <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">distinct</span>(sub)</code></pre></div>
<pre><code>## # A tibble: 3 x 1
##   sub   
##   &lt;chr&gt; 
## 1 Het   
## 2 nonHet
## 3 inart</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">r <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">model_matrix</span>(<span class="op">~</span><span class="st"> </span>sub) <span class="op">%&gt;%</span><span class="st">              </span><span class="co"># from modelr</span>
<span class="st">  </span><span class="kw">distinct</span>()</code></pre></div>
<pre><code>## # A tibble: 3 x 3
##   `(Intercept)` subinart subnonHet
##           &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
## 1             1        0         0
## 2             1        0         1
## 3             1        1         0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">  r <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">model_matrix</span>(<span class="op">~</span><span class="st"> </span>sub)</code></pre></div>
<pre><code>## # A tibble: 164,402 x 3
##    `(Intercept)` subinart subnonHet
##            &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
##  1             1        0         0
##  2             1        0         0
##  3             1        0         0
##  4             1        0         0
##  5             1        0         0
##  6             1        0         0
##  7             1        0         0
##  8             1        0         0
##  9             1        0         0
## 10             1        0         0
## # … with 164,392 more rows</code></pre>
<p>One of the values of the column is designated to be the intercept. In R, the default intercept is the first value of the vector, alphabetically. The other variables are called contrasts or dummy variables – they describe the difference in mean value when compared to the intercept. By adding the intercept and the regression coefficient, you get the estimated mean for that group. If the categorical variable has <span class="math inline">\(k\)</span> states, then there are <span class="math inline">\(k - 1\)</span> contrasts or dummy variables.</p>
<p>There are <a href="https://stats.idre.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/">many other strategies for encoding categorical variables</a>, but dummy coding is by far the most common – it helps that it is the R default.</p>
<p>Don’t worry too much about understanding dummy coding yet – just understand that it exists and that we will return to it in a later lesson.</p>
</div>
</div>
<div id="interpreting-the-model-fit" class="section level2">
<h2><span class="header-section-number">3.5</span> Interpreting the model fit</h2>
<p>There are two broad categories of how we process model fit: tables, and plotting. Tables are fine, but plotting is key. It is easy to feel like you understand a table while still getting it wrong.</p>
<p>Plotting the implications of your estimates will allow you to inquire about several things that are sometimes hard to read from tables:</p>
<ol style="list-style-type: decimal">
<li>Whether or not the model fitting procedure worked correctly.</li>
<li>The <em>absolute</em> magnitude, rather than merely <em>relative</em> magnitude, or a relationship between outcome and predictor.</li>
<li>The uncertainty surrounding an average relationship.</li>
<li>The uncertainty surrounding the implied predictions of the model, as these are distinct from mere parameter uncertainty.</li>
</ol>
<p>With practice extracting estimates from your model and plotting them, you can ask any question you can think of, for any model.</p>
<p>Let’s start by getting a basic summary of our posterior:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m_<span class="dv">2</span> <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather_draws</span>(b_Intercept, b_taxonBra, sigma) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">median_qi</span>()</code></pre></div>
<pre><code>## # A tibble: 3 x 7
##   .variable   .value .lower .upper .width .point .interval
##   &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    
## 1 b_Intercept  3.69   3.65   3.74    0.95 median qi       
## 2 b_taxonBra  -0.766 -0.823 -0.714   0.95 median qi       
## 3 sigma        0.840  0.822  0.859   0.95 median qi</code></pre>
<p>The first row corresponds to the model intercept, which we called <span class="math inline">\(\alpha\)</span>. This parameter corresponds to the expected log valve length when <span class="math inline">\(x = 0\)</span>. In the case of this model, this is easily interpreted as the expected log valve length of a Bivalve species.</p>
<p>The second row is the slope term <span class="math inline">\(\beta\)</span>. This parameter describes the expected change in log valve size associated with unit change in <span class="math inline">\(x\)</span>. In this case of this model, this parameter is easier to describe: this is an estimate of the expected difference in log valve length between Bivalves (<span class="math inline">\(x = 0\)</span>) and Brachiopods (<span class="math inline">\(x = 1\)</span>). By adding <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\alpha\)</span>, we get the estimate for Brachiopod expected log valve length.</p>
<p>The third line is the standard deviation term <span class="math inline">\(\sigma\)</span>, which describes the with of the distribution of log valve lengths. A useful trick for interpreting <span class="math inline">\(\sigma\)</span> is that about 95% of the probability of a Gaussian distribution lies between plus/minus two standard deviations from the mean. In this case, the estimate tells us that 95% of plausible log valve lengths lie within 1.68 log millimeters (<span class="math inline">\(2\sigma\)</span>) of the mean log valve length.</p>
<div id="linear-predictor" class="section level3">
<h3><span class="header-section-number">3.5.1</span> Linear predictor</h3>
<p>Our regression model describes a line with an intercept and a slope. As demonstrated above, this is true even in the case of a binary predictor – even though our predictor can only take one of two values, the formula still describes a line.</p>
<p>The function <code>brms::add_fitted_draws()</code> estimates the expected log valve length from the linear model part of our model. Remember that the linear model describes only the <em>mean</em> log valve length, and not the <em>spread</em> of log valve length. This function is a convenient way to help us visualize this part of our model.</p>
<p>Here’s an illustration of the linear relationship between taxonomic group and log valve size as described by the median estimates for each taxonomic group:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># parameters of the line</span>
d_fitted &lt;-<span class="st"> </span>d <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">add_fitted_draws</span>(<span class="dt">model =</span> m_<span class="dv">2</span>,
                   <span class="dt">n =</span> <span class="dv">100</span>) <span class="op">%&gt;%</span><span class="st">        </span><span class="co"># 100 posterior estimates</span>
<span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(taxon) <span class="op">%&gt;%</span><span class="st">                  </span><span class="co"># want to know taxon summary</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">summarize</span>(<span class="dt">value =</span> <span class="kw">median</span>(.value)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">taxon =</span> <span class="kw">recode</span>(taxon,
                          <span class="dt">Biv =</span> <span class="st">&#39;Bivalvia&#39;</span>,
                          <span class="dt">Bra =</span> <span class="st">&#39;Brachiopoda&#39;</span>)) <span class="co"># make text clearer </span>

d <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">taxon =</span> <span class="kw">recode</span>(taxon,
                        <span class="dt">Biv =</span> <span class="st">&#39;Bivalvia&#39;</span>,
                        <span class="dt">Bra =</span> <span class="st">&#39;Brachiopoda&#39;</span>)) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># make text clearer </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> taxon, <span class="dt">y =</span> size_log)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_violin</span>(<span class="dt">fill =</span> <span class="st">&#39;grey60&#39;</span>, <span class="dt">colour =</span> <span class="ot">NA</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_jitter</span>(<span class="dt">height =</span> <span class="dv">0</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data =</span> d_fitted,
            <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> taxon, <span class="dt">y =</span> value, <span class="dt">group =</span> <span class="dv">1</span>),
            <span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">colour =</span> <span class="st">&#39;blue&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&#39;taxon&#39;</span>, <span class="dt">y =</span> <span class="st">&#39;log valve length&#39;</span>)</code></pre></div>
<p><img src="paleo_book_files/figure-html/vis_linear_predictor_single-1.png" width="672" /></p>
<p>The above plot uses the median point estimates and includes none of our uncertainty about the relationship between the taxonomic groups and log valve length. There are a few ways we can demonstrate our uncertainty about the linear relationship.</p>
<p>We can plot multiple lines at the same time:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">d_fitted &lt;-<span class="st"> </span>d <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">add_fitted_draws</span>(<span class="dt">model =</span> m_<span class="dv">2</span>, 
                   <span class="dt">n =</span> <span class="dv">100</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">taxon =</span> <span class="kw">recode</span>(taxon,
                        <span class="dt">Biv =</span> <span class="st">&#39;Bivalvia&#39;</span>,
                        <span class="dt">Bra =</span> <span class="st">&#39;Brachiopoda&#39;</span>)) <span class="co"># make text clearer </span>
  
d <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">taxon =</span> <span class="kw">recode</span>(taxon,
                        <span class="dt">Biv =</span> <span class="st">&#39;Bivalvia&#39;</span>,
                        <span class="dt">Bra =</span> <span class="st">&#39;Brachiopoda&#39;</span>)) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># make text clearer </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> taxon, <span class="dt">y =</span> size_log)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_violin</span>(<span class="dt">fill =</span> <span class="st">&#39;grey60&#39;</span>, <span class="dt">colour =</span> <span class="ot">NA</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_jitter</span>(<span class="dt">height =</span> <span class="dv">0</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data =</span> d_fitted,
            <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> taxon, <span class="dt">y =</span> .value, <span class="dt">group =</span> .draw),
            <span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">colour =</span> <span class="st">&#39;blue&#39;</span>, <span class="dt">alpha =</span> <span class="fl">0.1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&#39;taxon&#39;</span>, <span class="dt">y =</span> <span class="st">&#39;log valve length&#39;</span>)</code></pre></div>
<p><img src="paleo_book_files/figure-html/vis_linear_predictor_uncertainty-1.png" width="672" /></p>
</div>
<div id="posterior-prediction" class="section level3">
<h3><span class="header-section-number">3.5.2</span> Posterior prediction</h3>
<p>An aspect of Bayesian models we’ve yet to discuss at length is the <em>posterior predictive distribution</em> <span class="math inline">\(p(\tilde{y} | y)\)</span>.</p>
<p>Prediction is when, given our model and parameter estimates, we want to estimate the outcome for some combination of covariates. The posterior predictive distribution is the distribution of outcomes defined by the plausible parameter values and data – instead of a single prediction, we have a distribution of predictions. For example, we might want to predict the log valve length of some species given our model and parameter estimates. For each possible value of a parameter, there is an implied distribution of outcomes. If we compute the distribution of outcomes for each value, this gives us a posterior predictive distribution.</p>
<p>Our full model describes log valve length as a Gaussian distribution with a mean (as a linear model) and a standard deviation. Our previous plots only considered the linear model aspect which describes the mean of the distribution, but there is still more information in our model that we’ve yet to consider: the estimated standard deviation <span class="math inline">\(\sigma\)</span>.</p>
<p>The <code>brms::add_predicted_draws()</code> function does this exactly. For each “new” observation, we obtain a series of predictions about that observations log valve length, not just the <em>expected</em> value of log valve length. This function is similar to the <code>brms::add_fitted_draws()</code> function we used above, but instead of predicting from the linear model we are predicting from the entire distribution.</p>
<p>Let’s illustrate this by comparing our log valve length data to our posterior predictive distribution for that data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">d_predicted &lt;-<span class="st"> </span>d <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">add_predicted_draws</span>(<span class="dt">model =</span> m_<span class="dv">2</span>,
                      <span class="dt">n =</span> <span class="dv">100</span>) <span class="op">%&gt;%</span>
<span class="kw">ungroup</span>() <span class="op">%&gt;%</span>
<span class="kw">mutate</span>(<span class="dt">taxon =</span> <span class="kw">recode</span>(taxon,
                      <span class="dt">Biv =</span> <span class="st">&#39;Bivalvia&#39;</span>,
                      <span class="dt">Bra =</span> <span class="st">&#39;Brachiopoda&#39;</span>)) 

d <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">taxon =</span> <span class="kw">recode</span>(taxon,
                        <span class="dt">Biv =</span> <span class="st">&#39;Bivalvia&#39;</span>,
                        <span class="dt">Bra =</span> <span class="st">&#39;Brachiopoda&#39;</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> taxon, <span class="dt">y =</span> size_log)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_violin</span>(<span class="dt">fill =</span> <span class="st">&#39;grey60&#39;</span>, <span class="dt">colour =</span> <span class="ot">NA</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_jitter</span>(<span class="dt">height =</span> <span class="dv">0</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_lineribbon</span>(<span class="dt">data =</span> d_predicted,
                  <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">y =</span> .prediction),
                  <span class="dt">.width =</span> <span class="kw">c</span>(<span class="fl">0.9</span>, <span class="fl">0.5</span>, <span class="fl">0.1</span>),
                  <span class="dt">size =</span> <span class="dv">0</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_fill_brewer</span>()</code></pre></div>
<p><img src="paleo_book_files/figure-html/vis_pp_dist-1.png" width="672" /></p>
</div>
<div id="posterior-predictive-tests" class="section level3">
<h3><span class="header-section-number">3.5.3</span> Posterior predictive tests</h3>
<p>What if we want to test how well our model fits specific parts of our data, and not just compare the similarities of their distributions? For example, how well does our model estimate the mean log valve size of each taxon?</p>
<p>Here’s the logic of posterior predictive tests: if data simulated from our posterior predictive distribution is able to reproduce a specific aspect of the original data, then the model <em>might</em> be doing something right. And if there are systematic failures in our model’s ability to predict the data, then the model <em>must</em> be doing something wrong.</p>
<p>Remember the warnings from last lesson:</p>
<blockquote>
<p>The goal when evaluating your model is not to test the truth of the model’s assumptions. Our model’s assumptions can never be exactly right and are not the true data generating process. Failure to prove that our model false is a failure of our imagination, not a success of our model. Additionally, a model doesn’t have to be true in order to produce precise and useful inference. Models are information processing machines, and there are parts of information that cannot be easily represented by framing our problem in terms of the truth of our assumptions.</p>
<p>Instead, our objective should be to test the model’s adequacy for some <em>purpose</em>. What are we trying to learn? This means asking and answering more questions than those originally used to construct our model. Think about what you know as a domain expert and compare it to your model; if there is a conflict you should update your model (likelihood and/or prior) to better reflect your domain knowledge. It is hard to give general advice on model evaluation as there are lots of different contexts for evaluating the adequacy of a model – prediction, comprehension, measurement, and persuasion. These are inherently <em>scientific questions</em>, not statistical questions. As I said earlier, robot’s can’t do this step for you.</p>
</blockquote>
<p>Here’s are a few example posterior predictive tests:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># summarize the original data</span>
d_sum &lt;-<span class="st"> </span>d <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(taxon) <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">summarize</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(size_log),
                   <span class="dt">sd =</span> <span class="kw">sd</span>(size_log),
                   <span class="dt">iqr =</span> <span class="kw">IQR</span>(size_log)) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># lots of options, none is best</span>
<span class="st">  </span><span class="kw">gather</span>(key, value, mean, sd, iqr) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">key =</span> <span class="kw">recode</span>(key,
                      <span class="dt">mean =</span> <span class="st">&#39;Mean&#39;</span>,
                      <span class="dt">sd =</span> <span class="st">&#39;Std Dev&#39;</span>,
                      <span class="dt">iqr =</span> <span class="st">&#39;Inter Quart Range&#39;</span>),
         <span class="dt">taxon =</span> <span class="kw">recode</span>(taxon,
                       <span class="dt">Biv =</span> <span class="st">&#39;Bivalvia&#39;</span>,
                       <span class="dt">Bra =</span> <span class="st">&#39;Brachiopoda&#39;</span>))

d <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">add_predicted_draws</span>(<span class="dt">model =</span> m_<span class="dv">2</span>,
                      <span class="dt">n =</span> <span class="dv">100</span>) <span class="op">%&gt;%</span><span class="st">     </span><span class="co"># calculate from n PPD draws</span>
<span class="st">  </span><span class="kw">group_by</span>(taxon, .draw) <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">summarize</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(.prediction),
                   <span class="dt">sd =</span> <span class="kw">sd</span>(.prediction),
                   <span class="dt">iqr =</span> <span class="kw">IQR</span>(.prediction)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather</span>(key, value, mean, sd, iqr) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">key =</span> <span class="kw">recode</span>(key,
                      <span class="dt">mean =</span> <span class="st">&#39;Mean&#39;</span>,
                      <span class="dt">sd =</span> <span class="st">&#39;Std Dev&#39;</span>,
                      <span class="dt">iqr =</span> <span class="st">&#39;Inter Quart Range&#39;</span>),
         <span class="dt">taxon =</span> <span class="kw">recode</span>(taxon,
                        <span class="dt">Biv =</span> <span class="st">&#39;Bivalvia&#39;</span>,
                        <span class="dt">Bra =</span> <span class="st">&#39;Brachiopoda&#39;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> value)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">fill =</span> <span class="st">&#39;grey80&#39;</span>,
               <span class="dt">colour =</span> <span class="ot">NA</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">data =</span> d_sum,
             <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">xintercept =</span> value),
             <span class="dt">size =</span> <span class="fl">1.5</span>,
             <span class="dt">colour =</span> <span class="st">&#39;grey20&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_grid</span>(taxon <span class="op">~</span><span class="st"> </span>key, <span class="dt">scales =</span> <span class="st">&#39;free&#39;</span>, <span class="dt">switch =</span> <span class="st">&#39;y&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&#39;&lt;stat&gt; log valve length&#39;</span>)</code></pre></div>
<p><img src="paleo_book_files/figure-html/pp_tests_multi-1.png" width="672" /></p>
<p>Where does our model do well? Where does our model do poorly? Why? How could we modify our model to overcome these failures?</p>
<p>Even though it should be obvious and mandatory to do go through with and report an extended posterior predictive checking process, it is relatively rare in macroevolutionary biology and paleobiology. Indeed, so rare that posterior predictive checking, if done creatively and well, can get you a paper: <a href="https://www.journals.uchicago.edu/doi/abs/10.1086/696265">Example 1</a>, <a href="https://www.journals.uchicago.edu/doi/abs/10.1086/682022">Example 2</a>, <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1558-5646.2011.01574.x">Example 3</a>.</p>
</div>
</div>
<div id="summary-2" class="section level2">
<h2><span class="header-section-number">3.6</span> Summary</h2>
<p>To review, this lesson was an exercise in developing, communicating, and summarizing a Bayesian model – specifically, a linear regression model. We’ve slowly developed a linear regression model by expanding a Gaussian distribution to include the effects of predictor information. We first developed our model using the symbolic representation of a statistical model, and we then implemented our model using functions from <strong>brms</strong>. We explored a number of ways of representing and visualizing posterior distributions; these included tables and figures. We briefly covered the difference between fitted predictions and the posterior predictive distribution. Finally, we discussed the concept of posterior predictive tests.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction-to-bayesian-data-analysis.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="reg-continue.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": [["analytical_paleobiology.pdf", "PDF"], ["analytical_paleobiology.epub", "EPUB"]],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
